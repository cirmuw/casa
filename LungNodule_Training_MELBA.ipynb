{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "#import active_dynamicmemory.ActiveDynamicMemoryModel as activedm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import pytorch_lightning as pl\n",
    "import sklearn \n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from py_jotools import mut, slurm, cache\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import hashlib\n",
    "import dill\n",
    "#import active_catinous.utils as cutils\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datasets.ContinuousDataset import LIDCContinuous\n",
    "from datasets.BatchDataset import LIDCBatch\n",
    "import yaml\n",
    "import active_dynamicmemory.runutils as rutils\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_config(configfile, remote=False, runs=None, jobarray=False):\n",
    "    with open(configfile) as f:\n",
    "        params = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    if remote:\n",
    "        with open('training_configs/slurm_config.yml') as s:\n",
    "            sparams = yaml.load(s, Loader=yaml.FullLoader)\n",
    "\n",
    "    if jobarray:\n",
    "        sparams['qos'] = 'jobarray'\n",
    "\n",
    "    if runs is None:\n",
    "        if remote:\n",
    "            print('scheduling job to CIR cluster...')\n",
    "            slurm.srun(rutils.trained_model, [params['trainparams'], params['settings']], params=sparams, remote=True)\n",
    "        else:\n",
    "            model, logs, df_mem, exp_name = rutils.trained_model(params['trainparams'], params['settings'])\n",
    "            print('successfully trained model', exp_name)\n",
    "    else:\n",
    "        for i in range(runs):\n",
    "            params['trainparams']['seed'] = i+1\n",
    "            params['trainparams']['run_postfix'] = i+1\n",
    "            if remote:\n",
    "                print('scheduling job to CIR cluster...')\n",
    "                slurm.srun(rutils.trained_model, [params['trainparams'], params['settings']], params=sparams, remote=True)\n",
    "            else:\n",
    "                model, logs, df_mem, exp_name = rutils.trained_model(params['trainparams'], params['settings'])\n",
    "                print('successfully trained model', exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_params(params, remote=False, runs=None, jobarray=False):\n",
    "    if remote:\n",
    "        with open('training_configs/slurm_config.yml') as s:\n",
    "            sparams = yaml.load(s, Loader=yaml.FullLoader)\n",
    "\n",
    "    if jobarray:\n",
    "        sparams['qos'] = 'jobarray'\n",
    "\n",
    "    if runs is None:\n",
    "        if remote:\n",
    "            print('scheduling job to CIR cluster...')\n",
    "            slurm.srun(rutils.trained_model, [params['trainparams'], params['settings']], params=sparams, remote=True)\n",
    "        else:\n",
    "            model, logs, df_mem, exp_name = rutils.trained_model(params['trainparams'], params['settings'])\n",
    "            print('successfully trained model', exp_name)\n",
    "    else:\n",
    "        for i in range(runs):\n",
    "            params['trainparams']['seed'] = i+1\n",
    "            params['trainparams']['run_postfix'] = i+1\n",
    "            if remote:\n",
    "                print('scheduling job to CIR cluster...')\n",
    "                slurm.srun(rutils.trained_model, [params['trainparams'], params['settings']], params=sparams, remote=True)\n",
    "            else:\n",
    "                model, logs, df_mem, exp_name = rutils.trained_model(params['trainparams'], params['settings'])\n",
    "                print('successfully trained model', exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  41%|████▏     | 121/292 [02:28<03:30,  1.23s/it, loss=0.0508, v_num=0]"
     ]
    }
   ],
   "source": [
    "with open(f'./training_configs/lidc_joint.yml') as f:\n",
    "    params = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "for scanner in ['ges', 'geb', 'sie', 'lndb']:\n",
    "    params['trainparams']['scanner'] = scanner\n",
    "    \n",
    "    train_params(params, remote=True, runs=5, jobarray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ges'] scanners\n",
      "['base'] split\n",
      "gram matrix init elements (262144,)\n",
      "fit sparse projection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | model      | FasterRCNN | 41.3 M\n",
      "1 | stylemodel | ResNet     | 25.6 M\n",
      "------------------------------------------\n",
      "66.6 M    Trainable params\n",
      "222 K     Non-trainable params\n",
      "66.9 M    Total params\n",
      "267.445   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center [ 3.85399991e-20 -3.81164826e-20  0.00000000e+00  3.64224167e-20\n",
      "  4.40457133e-20 -4.44692297e-20  3.49401091e-20 -2.10699446e-20\n",
      " -1.65171425e-20 -2.38492714e-20 -3.81164826e-21 -7.62329653e-21\n",
      "  1.49355731e-20  1.69406589e-21 -8.99972506e-21 -1.10114283e-20\n",
      " -2.51462906e-21  4.34104385e-21 -6.14098887e-21 -1.79994501e-21\n",
      " -1.32348898e-21 -8.54312137e-21 -2.03287907e-20 -3.99693672e-21\n",
      "  1.37642854e-21 -3.49401091e-21  0.00000000e+00 -6.35274710e-21\n",
      " -9.21148330e-21 -2.75285708e-21] {0: 2.70253565799824e-07}\n",
      "trans_init [[-1.61773531e-03 -4.32922272e-04 -5.08038319e-04  2.05812119e-04\n",
      "   6.97969107e-05 -9.91708495e-05 -5.76519327e-04 -1.72156209e-04\n",
      "   1.07971018e-04  9.68210572e-05  7.61883514e-05  2.49413074e-04\n",
      "  -3.35260665e-05 -2.41690757e-04 -5.37651261e-05  1.52237440e-04\n",
      "  -1.01175087e-04 -1.00548995e-04 -1.36922855e-04 -7.42818245e-05\n",
      "   4.58197698e-05  3.79982267e-05  1.42617005e-04  1.23625815e-04\n",
      "   1.42512712e-04  1.22316002e-04  2.04166117e-05  3.49318555e-05\n",
      "  -7.68786077e-05 -3.37556067e-05]\n",
      " [ 2.27042864e-04  2.08864549e-04  5.84240035e-04 -7.70537885e-04\n",
      "   9.98313141e-04  1.41503592e-04 -2.01179388e-04  2.31374485e-04\n",
      "  -1.35566469e-05 -5.58077260e-05 -5.10298000e-05 -1.39393511e-04\n",
      "   1.14652617e-04 -1.42298188e-04 -1.08731700e-04 -4.45144852e-05\n",
      "  -2.02678044e-05 -2.60515012e-05  7.30497511e-05 -9.04358740e-07\n",
      "  -1.12215658e-04  7.31837058e-05 -1.78389610e-04 -2.91335868e-05\n",
      "   1.01440916e-04  7.33387808e-05  6.29220624e-05 -8.38169135e-06\n",
      "  -1.38072831e-04  1.44514676e-04]\n",
      " [-1.20970584e-04  2.77237905e-04  7.97630856e-04 -3.12050414e-04\n",
      "   5.55323873e-04 -2.12994073e-04 -7.09016955e-04  1.76610510e-04\n",
      "   5.83597259e-05 -2.43562006e-04 -1.45282483e-04  1.37732583e-04\n",
      "  -1.65465782e-04  1.03071525e-04  2.62430198e-04 -7.62757940e-05\n",
      "   8.70230283e-05 -1.54685205e-04 -7.81973490e-05 -4.79865013e-05\n",
      "   6.25272242e-05 -9.46588147e-05 -2.61671172e-05  6.75631397e-05\n",
      "   4.82301541e-05 -3.44746487e-05  8.90461957e-05  1.01562786e-04\n",
      "  -7.51085528e-05 -6.73578940e-05]\n",
      " [ 9.39093611e-04 -4.98096764e-05 -1.61027097e-04  3.30291377e-04\n",
      "   1.78603585e-04  7.63928902e-04 -5.84109438e-04  3.45201016e-04\n",
      "   3.28876481e-04 -3.30634946e-04 -6.40116403e-06 -1.92758701e-04\n",
      "   5.06508313e-05 -1.84900852e-04  1.64902856e-04 -7.05175727e-05\n",
      "   2.54788263e-04 -1.23367176e-04 -4.04790917e-05  2.77796791e-04\n",
      "   8.54736249e-05  1.45066821e-05 -1.41581064e-05  4.99937605e-05\n",
      "   2.39073688e-06 -6.00651657e-05  4.89782353e-05 -3.72672713e-05\n",
      "  -6.60536877e-05  2.64737380e-05]\n",
      " [ 1.14099261e-04 -1.31602167e-03  1.41521706e-03 -9.46975562e-04\n",
      "   1.10103178e-04 -1.10338242e-05  2.64837560e-04 -9.73998575e-05\n",
      "   2.48231269e-04  1.55894709e-04  2.08804350e-04 -1.50402190e-04\n",
      "   2.94512646e-04 -1.96987348e-04  1.75813528e-04  3.44554384e-05\n",
      "  -1.63856367e-04 -5.18906009e-05 -2.10214154e-04 -7.45764452e-05\n",
      "  -1.30125544e-04  2.35039249e-04  1.17768243e-04  1.10282971e-04\n",
      "  -7.77090599e-06  3.30919671e-04  5.27168095e-05  1.77663473e-04\n",
      "   3.02789439e-05 -4.70049525e-05]]\n",
      "lidc_cont_lungnodulesfinallndbBig_basemodel_batch_memory_tf08_1_9cf36c6c67\n",
      "/project/catinous/active_catinous/MELBA/output/trained_models/lidc_cont_lungnodulesfinallndbBig_basemodel_batch_memory_tf08_1_9cf36c6c67.pt\n",
      "Validation sanity check: 0it [00:00, ?it/s]['ges' 'geb' 'sie' 'lndb'] scanners\n",
      "['val'] split\n",
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mperkonigg/venv_test/venv/local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mperkonigg/venv_test/venv/local/lib/python3.6/site-packages/torchvision/ops/boxes.py:101: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  keep = keep.nonzero().squeeze(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ges', 'geb', 'sie', 'lndb']                                         \n",
      "Epoch 0:   0%|          | 0/616 [00:00<?, ?it/s] predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "Epoch 0:   0%|          | 1/616 [00:01<14:03,  1.37s/it, loss=nan, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mperkonigg/venv_test/venv/local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: training_step returned None. If this was on purpose, ignore this warning...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:   0%|          | 2/616 [00:01<08:17,  1.23it/s, loss=nan, v_num=0]predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain -1\n",
      "Epoch 0:   0%|          | 3/616 [00:01<06:22,  1.60it/s, loss=nan, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain -1\n",
      "Epoch 0:   1%|          | 4/616 [00:02<05:15,  1.94it/s, loss=nan, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:   1%|          | 5/616 [00:02<04:35,  2.22it/s, loss=nan, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:   1%|          | 6/616 [00:02<04:06,  2.47it/s, loss=nan, v_num=0]predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "Epoch 0:   1%|          | 7/616 [00:02<03:51,  2.63it/s, loss=nan, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:   1%|▏         | 8/616 [00:02<03:41,  2.75it/s, loss=nan, v_num=0]predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:   1%|▏         | 9/616 [00:03<03:30,  2.89it/s, loss=nan, v_num=0]predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:   2%|▏         | 10/616 [00:03<03:22,  2.99it/s, loss=nan, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "outlier distance 0.020802932314444342\n",
      "new center {0: array([ 3.85399991e-20, -3.81164826e-20,  0.00000000e+00,  3.64224167e-20,\n",
      "        4.40457133e-20, -4.44692297e-20,  3.49401091e-20, -2.10699446e-20,\n",
      "       -1.65171425e-20, -2.38492714e-20, -3.81164826e-21, -7.62329653e-21,\n",
      "        1.49355731e-20,  1.69406589e-21, -8.99972506e-21, -1.10114283e-20,\n",
      "       -2.51462906e-21,  4.34104385e-21, -6.14098887e-21, -1.79994501e-21,\n",
      "       -1.32348898e-21, -8.54312137e-21, -2.03287907e-20, -3.99693672e-21,\n",
      "        1.37642854e-21, -3.49401091e-21,  0.00000000e+00, -6.35274710e-21,\n",
      "       -9.21148330e-21, -2.75285708e-21]), 1: array([-4.31657144e-04,  2.33725901e-03, -7.66082792e-04, -8.21060711e-04,\n",
      "       -1.71836049e-03, -2.77380606e-04,  6.64274759e-04,  1.10728798e-03,\n",
      "       -4.40664459e-04, -6.20084145e-04,  7.88546783e-04,  2.29767333e-04,\n",
      "        4.13076490e-05, -3.64234587e-04, -2.69264355e-04,  7.89203357e-05,\n",
      "       -9.02115629e-05, -5.85181438e-05,  1.14905082e-04, -7.32911449e-05,\n",
      "        1.18300514e-04, -2.70810011e-05, -1.17187207e-04,  5.46022697e-05,\n",
      "       -1.96268963e-04, -1.38127462e-04,  2.97959940e-04,  3.64553805e-04,\n",
      "        6.71244129e-05, -5.00347968e-05])} {0: 2.70253565799824e-07, 1: 1.4153925867691526e-07}\n",
      "found new domain 1 ges\n",
      "found new domain 1 ges\n",
      "found new domain 1 ges\n",
      "found new domain 1 ges\n",
      "found new domain 1 ges\n",
      "found new domain 1 ges\n",
      "found new domain 1 ges\n",
      "found new domain 1 ges\n",
      "found new domain 1 ges\n",
      "0.36602366156876087 1\n",
      "Epoch 0:   2%|▏         | 11/616 [00:05<04:43,  2.13it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 1\n",
      "predicted domain -1\n",
      "Epoch 0:   2%|▏         | 12/616 [00:05<04:32,  2.22it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 1\n",
      "predicted domain 1\n",
      "Epoch 0:   2%|▏         | 13/616 [00:05<04:20,  2.32it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:   2%|▏         | 14/616 [00:05<04:09,  2.41it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:   2%|▏         | 15/616 [00:05<04:00,  2.50it/s, loss=0.0771, v_num=0]predicted domain 1\n",
      "predicted domain 0\n",
      "predicted domain 1\n",
      "predicted domain 0\n",
      "Epoch 0:   3%|▎         | 16/616 [00:06<03:53,  2.57it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:   3%|▎         | 17/616 [00:06<03:45,  2.65it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain -1\n",
      "Epoch 0:   3%|▎         | 18/616 [00:06<03:39,  2.72it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 1\n",
      "Epoch 0:   3%|▎         | 19/616 [00:06<03:34,  2.78it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 1\n",
      "Epoch 0:   3%|▎         | 20/616 [00:07<03:29,  2.85it/s, loss=0.0771, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:   4%|▎         | 22/616 [00:07<03:22,  2.93it/s, loss=0.0771, v_num=0]\n",
      "Validating:   6%|▌         | 2/36 [00:00<00:12,  2.65it/s]\u001b[A\n",
      "Epoch 0:   4%|▍         | 24/616 [00:07<03:14,  3.05it/s, loss=0.0771, v_num=0]\n",
      "Validating:  11%|█         | 4/36 [00:01<00:09,  3.55it/s]\u001b[A\n",
      "Epoch 0:   4%|▍         | 26/616 [00:08<03:07,  3.15it/s, loss=0.0771, v_num=0]\n",
      "Validating:  17%|█▋        | 6/36 [00:01<00:07,  4.22it/s]\u001b[A\n",
      "Epoch 0:   5%|▍         | 28/616 [00:08<03:01,  3.23it/s, loss=0.0771, v_num=0]\n",
      "Validating:  22%|██▏       | 8/36 [00:01<00:06,  4.56it/s]\u001b[A\n",
      "Epoch 0:   5%|▍         | 30/616 [00:09<02:56,  3.31it/s, loss=0.0771, v_num=0]\n",
      "Validating:  28%|██▊       | 10/36 [00:02<00:05,  4.77it/s]\u001b[A\n",
      "Epoch 0:   5%|▌         | 32/616 [00:09<02:52,  3.39it/s, loss=0.0771, v_num=0]\n",
      "Validating:  33%|███▎      | 12/36 [00:02<00:04,  5.02it/s]\u001b[A\n",
      "Epoch 0:   6%|▌         | 34/616 [00:09<02:48,  3.46it/s, loss=0.0771, v_num=0]\n",
      "Validating:  39%|███▉      | 14/36 [00:02<00:04,  5.12it/s]\u001b[A\n",
      "Epoch 0:   6%|▌         | 36/616 [00:10<02:44,  3.52it/s, loss=0.0771, v_num=0]\n",
      "Validating:  44%|████▍     | 16/36 [00:03<00:03,  5.04it/s]\u001b[A\n",
      "Epoch 0:   6%|▌         | 38/616 [00:10<02:41,  3.58it/s, loss=0.0771, v_num=0]\n",
      "Validating:  50%|█████     | 18/36 [00:03<00:03,  5.10it/s]\u001b[A\n",
      "Epoch 0:   6%|▋         | 40/616 [00:11<02:38,  3.63it/s, loss=0.0771, v_num=0]\n",
      "Validating:  56%|█████▌    | 20/36 [00:04<00:03,  5.13it/s]\u001b[A\n",
      "Epoch 0:   7%|▋         | 42/616 [00:11<02:35,  3.69it/s, loss=0.0771, v_num=0]\n",
      "Validating:  61%|██████    | 22/36 [00:04<00:02,  5.20it/s]\u001b[A\n",
      "Epoch 0:   7%|▋         | 44/616 [00:11<02:32,  3.74it/s, loss=0.0771, v_num=0]\n",
      "Validating:  67%|██████▋   | 24/36 [00:04<00:02,  5.33it/s]\u001b[A\n",
      "Epoch 0:   7%|▋         | 46/616 [00:12<02:30,  3.79it/s, loss=0.0771, v_num=0]\n",
      "Validating:  72%|███████▏  | 26/36 [00:05<00:01,  5.17it/s]\u001b[A\n",
      "Epoch 0:   8%|▊         | 48/616 [00:12<02:28,  3.83it/s, loss=0.0771, v_num=0]\n",
      "Validating:  78%|███████▊  | 28/36 [00:05<00:01,  5.24it/s]\u001b[A\n",
      "Epoch 0:   8%|▊         | 50/616 [00:12<02:26,  3.87it/s, loss=0.0771, v_num=0]\n",
      "Validating:  83%|████████▎ | 30/36 [00:06<00:01,  5.30it/s]\u001b[A\n",
      "Epoch 0:   8%|▊         | 52/616 [00:13<02:24,  3.91it/s, loss=0.0771, v_num=0]\n",
      "Validating:  89%|████████▉ | 32/36 [00:06<00:00,  5.28it/s]\u001b[A\n",
      "Epoch 0:   9%|▉         | 54/616 [00:13<02:22,  3.95it/s, loss=0.0771, v_num=0]\n",
      "Validating:  94%|█████████▍| 34/36 [00:06<00:00,  5.16it/s]\u001b[A\n",
      "Epoch 0:   9%|▉         | 57/616 [00:14<02:22,  3.93it/s, loss=0.0771, v_num=0]\n",
      "                                                           \u001b[Apredicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:   9%|▉         | 58/616 [00:14<02:22,  3.93it/s, loss=0.0771, v_num=0]predicted domain 1\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:  10%|▉         | 59/616 [00:14<02:21,  3.94it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:  10%|▉         | 60/616 [00:15<02:20,  3.94it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:  10%|▉         | 61/616 [00:15<02:20,  3.94it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "Epoch 0:  10%|█         | 62/616 [00:15<02:19,  3.96it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:  10%|█         | 63/616 [00:15<02:19,  3.97it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:  10%|█         | 64/616 [00:16<02:18,  3.98it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:  11%|█         | 65/616 [00:16<02:18,  3.99it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 1\n",
      "Epoch 0:  11%|█         | 66/616 [00:16<02:18,  3.98it/s, loss=0.0771, v_num=0]predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:  11%|█         | 67/616 [00:16<02:18,  3.98it/s, loss=0.0771, v_num=0]new shift to geb\n",
      "predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain 1\n",
      "Epoch 0:  11%|█         | 68/616 [00:18<02:31,  3.62it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 1\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:  11%|█         | 69/616 [00:18<02:30,  3.64it/s, loss=0.0771, v_num=0]predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain -1\n",
      "Epoch 0:  11%|█▏        | 70/616 [00:19<02:29,  3.65it/s, loss=0.0771, v_num=0]predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "outlier distance 0.03943135607423613\n",
      "Epoch 0:  12%|█▏        | 71/616 [00:19<02:29,  3.65it/s, loss=0.0771, v_num=0]predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "outlier distance 0.03223129954707785\n",
      "Epoch 0:  12%|█▏        | 72/616 [00:19<02:28,  3.66it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain -1\n",
      "outlier distance 0.027335993307320564\n",
      "Epoch 0:  12%|█▏        | 73/616 [00:19<02:27,  3.68it/s, loss=0.0771, v_num=0]predicted domain 0\n",
      "predicted domain 1\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "outlier distance 0.026432838134522487\n",
      "Epoch 0:  12%|█▏        | 74/616 [00:20<02:27,  3.68it/s, loss=0.0771, v_num=0]predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "outlier distance 0.02333385840225513\n",
      "new center {0: array([ 3.85399991e-20, -3.81164826e-20,  0.00000000e+00,  3.64224167e-20,\n",
      "        4.40457133e-20, -4.44692297e-20,  3.49401091e-20, -2.10699446e-20,\n",
      "       -1.65171425e-20, -2.38492714e-20, -3.81164826e-21, -7.62329653e-21,\n",
      "        1.49355731e-20,  1.69406589e-21, -8.99972506e-21, -1.10114283e-20,\n",
      "       -2.51462906e-21,  4.34104385e-21, -6.14098887e-21, -1.79994501e-21,\n",
      "       -1.32348898e-21, -8.54312137e-21, -2.03287907e-20, -3.99693672e-21,\n",
      "        1.37642854e-21, -3.49401091e-21,  0.00000000e+00, -6.35274710e-21,\n",
      "       -9.21148330e-21, -2.75285708e-21]), 1: array([-4.31657144e-04,  2.33725901e-03, -7.66082792e-04, -8.21060711e-04,\n",
      "       -1.71836049e-03, -2.77380606e-04,  6.64274759e-04,  1.10728798e-03,\n",
      "       -4.40664459e-04, -6.20084145e-04,  7.88546783e-04,  2.29767333e-04,\n",
      "        4.13076490e-05, -3.64234587e-04, -2.69264355e-04,  7.89203357e-05,\n",
      "       -9.02115629e-05, -5.85181438e-05,  1.14905082e-04, -7.32911449e-05,\n",
      "        1.18300514e-04, -2.70810011e-05, -1.17187207e-04,  5.46022697e-05,\n",
      "       -1.96268963e-04, -1.38127462e-04,  2.97959940e-04,  3.64553805e-04,\n",
      "        6.71244129e-05, -5.00347968e-05]), 2: array([-7.40261814e-04,  4.07224397e-03, -1.58285956e-04, -2.86254347e-04,\n",
      "       -3.12603122e-03,  9.73200064e-04,  4.58091478e-04,  3.15620720e-03,\n",
      "       -7.14553077e-04,  4.76833181e-05,  1.31803748e-03,  3.23168254e-04,\n",
      "        3.20065740e-04, -8.26350200e-04, -4.41757518e-04, -2.41630361e-04,\n",
      "       -7.19940038e-04, -6.35909064e-05,  2.94337321e-04, -6.95059403e-05,\n",
      "       -3.13070442e-04,  5.60610862e-04,  3.79226326e-04,  4.59391874e-05,\n",
      "       -4.80819050e-04, -3.83099152e-04,  4.81637685e-04,  5.88769471e-04,\n",
      "       -4.12695902e-04, -7.45011849e-04])} {0: 2.70253565799824e-07, 1: 1.4153925867691526e-07, 2: 2.4966888554267227e-07}\n",
      "found new domain 2 geb\n",
      "found new domain 2 geb\n",
      "found new domain 2 geb\n",
      "found new domain 2 geb\n",
      "found new domain 2 geb\n",
      "found new domain 2 geb\n",
      "found new domain 2 geb\n",
      "found new domain 2 geb\n",
      "found new domain 2 geb\n",
      "0.22749154176563025 2\n",
      "Epoch 0:  12%|█▏        | 75/616 [00:21<02:36,  3.46it/s, loss=0.0588, v_num=0]predicted domain 2\n",
      "inserting sample geb\n",
      "predicted domain 2\n",
      "inserting sample geb\n",
      "predicted domain 2\n",
      "inserting sample geb\n",
      "predicted domain -1\n",
      "outlier distance 0.044151383669513176\n",
      "0.11992377787828445 2\n",
      "Epoch 0:  12%|█▏        | 76/616 [00:22<02:42,  3.32it/s, loss=0.0814, v_num=0]predicted domain 2\n",
      "inserting sample geb\n",
      "predicted domain -1\n",
      "predicted domain 2\n",
      "inserting sample geb\n",
      "predicted domain 2\n",
      "inserting sample geb\n",
      "outlier distance 0.04096082303390839\n",
      "0.25433988605839164 2\n",
      "Epoch 0:  13%|█▎        | 78/616 [00:24<02:46,  3.24it/s, loss=0.0743, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/36 [00:00<00:15,  2.20it/s]\u001b[A\n",
      "Epoch 0:  13%|█▎        | 80/616 [00:24<02:45,  3.23it/s, loss=0.0743, v_num=0]\n",
      "Validating:   8%|▊         | 3/36 [00:00<00:10,  3.10it/s]\u001b[A\n",
      "Epoch 0:  13%|█▎        | 82/616 [00:25<02:43,  3.26it/s, loss=0.0743, v_num=0]\n",
      "Validating:  14%|█▍        | 5/36 [00:01<00:08,  3.86it/s]\u001b[A\n",
      "Epoch 0:  14%|█▎        | 84/616 [00:25<02:41,  3.29it/s, loss=0.0743, v_num=0]\n",
      "Validating:  19%|█▉        | 7/36 [00:01<00:06,  4.38it/s]\u001b[A\n",
      "Epoch 0:  14%|█▍        | 86/616 [00:25<02:39,  3.32it/s, loss=0.0743, v_num=0]\n",
      "Validating:  25%|██▌       | 9/36 [00:02<00:05,  4.78it/s]\u001b[A\n",
      "Epoch 0:  14%|█▍        | 88/616 [00:26<02:37,  3.34it/s, loss=0.0743, v_num=0]\n",
      "Validating:  31%|███       | 11/36 [00:02<00:05,  4.92it/s]\u001b[A\n",
      "Epoch 0:  15%|█▍        | 90/616 [00:26<02:36,  3.37it/s, loss=0.0743, v_num=0]\n",
      "Validating:  36%|███▌      | 13/36 [00:02<00:04,  5.00it/s]\u001b[A\n",
      "Epoch 0:  15%|█▍        | 92/616 [00:27<02:34,  3.39it/s, loss=0.0743, v_num=0]\n",
      "Validating:  42%|████▏     | 15/36 [00:03<00:04,  4.99it/s]\u001b[A\n",
      "Epoch 0:  15%|█▌        | 94/616 [00:27<02:32,  3.42it/s, loss=0.0743, v_num=0]\n",
      "Validating:  47%|████▋     | 17/36 [00:03<00:03,  5.07it/s]\u001b[A\n",
      "Epoch 0:  16%|█▌        | 96/616 [00:27<02:31,  3.44it/s, loss=0.0743, v_num=0]\n",
      "Validating:  53%|█████▎    | 19/36 [00:03<00:03,  5.12it/s]\u001b[A\n",
      "Epoch 0:  16%|█▌        | 98/616 [00:28<02:29,  3.46it/s, loss=0.0743, v_num=0]\n",
      "Validating:  58%|█████▊    | 21/36 [00:04<00:02,  5.21it/s]\u001b[A\n",
      "Epoch 0:  16%|█▌        | 100/616 [00:28<02:27,  3.49it/s, loss=0.0743, v_num=0]\n",
      "Validating:  64%|██████▍   | 23/36 [00:04<00:02,  5.25it/s]\u001b[A\n",
      "Epoch 0:  17%|█▋        | 102/616 [00:29<02:26,  3.51it/s, loss=0.0743, v_num=0]\n",
      "Validating:  69%|██████▉   | 25/36 [00:05<00:02,  5.21it/s]\u001b[A\n",
      "Epoch 0:  17%|█▋        | 104/616 [00:29<02:24,  3.53it/s, loss=0.0743, v_num=0]\n",
      "Validating:  75%|███████▌  | 27/36 [00:05<00:01,  5.19it/s]\u001b[A\n",
      "Epoch 0:  17%|█▋        | 106/616 [00:29<02:23,  3.55it/s, loss=0.0743, v_num=0]\n",
      "Validating:  81%|████████  | 29/36 [00:05<00:01,  5.18it/s]\u001b[A\n",
      "Epoch 0:  18%|█▊        | 108/616 [00:30<02:22,  3.57it/s, loss=0.0743, v_num=0]\n",
      "Validating:  86%|████████▌ | 31/36 [00:06<00:00,  5.09it/s]\u001b[A\n",
      "Epoch 0:  18%|█▊        | 110/616 [00:30<02:20,  3.59it/s, loss=0.0743, v_num=0]\n",
      "Validating:  92%|█████████▏| 33/36 [00:06<00:00,  5.02it/s]\u001b[A\n",
      "Epoch 0:  18%|█▊        | 112/616 [00:31<02:19,  3.61it/s, loss=0.0743, v_num=0]\n",
      "Epoch 0:  19%|█▊        | 114/616 [00:31<02:19,  3.59it/s, loss=0.0743, v_num=0]\n",
      "                                                           \u001b[Apredicted domain -1\n",
      "predicted domain 2\n",
      "inserting sample geb\n",
      "predicted domain 2\n",
      "inserting sample geb\n",
      "predicted domain 2\n",
      "inserting sample geb\n",
      "outlier distance 0.03833028620718759\n",
      "0.2662210438142434 2\n",
      "Epoch 0:  19%|█▊        | 115/616 [00:33<02:23,  3.48it/s, loss=0.0676, v_num=0]predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain 2\n",
      "inserting sample geb\n",
      "predicted domain 2\n",
      "inserting sample geb\n",
      "outlier distance 0.03526006496564199\n",
      "0.3656836572776452 2\n",
      "Epoch 0:  19%|█▉        | 116/616 [00:34<02:27,  3.39it/s, loss=0.0717, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "outlier distance 0.03526006496564199\n",
      "Epoch 0:  19%|█▉        | 117/616 [00:34<02:26,  3.40it/s, loss=0.0717, v_num=0]predicted domain -1\n",
      "predicted domain 2\n",
      "predicted domain -1\n",
      "predicted domain 2\n",
      "outlier distance 0.030630607231109178\n",
      "Epoch 0:  19%|█▉        | 118/616 [00:34<02:26,  3.41it/s, loss=0.0717, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain -1\n",
      "outlier distance 0.025971531526072893\n",
      "Epoch 0:  19%|█▉        | 119/616 [00:34<02:25,  3.41it/s, loss=0.0717, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "outlier distance 0.025971531526072893\n",
      "Epoch 0:  19%|█▉        | 120/616 [00:35<02:25,  3.42it/s, loss=0.0717, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "outlier distance 0.027671393409034413\n",
      "Epoch 0:  20%|█▉        | 121/616 [00:35<02:24,  3.43it/s, loss=0.0717, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "outlier distance 0.027671393409034413\n",
      "Epoch 0:  20%|█▉        | 122/616 [00:35<02:23,  3.43it/s, loss=0.0717, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "outlier distance 0.02767666744272301\n",
      "Epoch 0:  20%|█▉        | 123/616 [00:35<02:23,  3.44it/s, loss=0.0717, v_num=0]predicted domain -1\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "outlier distance 0.027663782896856663\n",
      "Epoch 0:  20%|██        | 124/616 [00:36<02:22,  3.44it/s, loss=0.0717, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain -1\n",
      "predicted domain 2\n",
      "outlier distance 0.022323002768502413\n",
      "new center {0: array([ 3.85399991e-20, -3.81164826e-20,  0.00000000e+00,  3.64224167e-20,\n",
      "        4.40457133e-20, -4.44692297e-20,  3.49401091e-20, -2.10699446e-20,\n",
      "       -1.65171425e-20, -2.38492714e-20, -3.81164826e-21, -7.62329653e-21,\n",
      "        1.49355731e-20,  1.69406589e-21, -8.99972506e-21, -1.10114283e-20,\n",
      "       -2.51462906e-21,  4.34104385e-21, -6.14098887e-21, -1.79994501e-21,\n",
      "       -1.32348898e-21, -8.54312137e-21, -2.03287907e-20, -3.99693672e-21,\n",
      "        1.37642854e-21, -3.49401091e-21,  0.00000000e+00, -6.35274710e-21,\n",
      "       -9.21148330e-21, -2.75285708e-21]), 1: array([-4.31657144e-04,  2.33725901e-03, -7.66082792e-04, -8.21060711e-04,\n",
      "       -1.71836049e-03, -2.77380606e-04,  6.64274759e-04,  1.10728798e-03,\n",
      "       -4.40664459e-04, -6.20084145e-04,  7.88546783e-04,  2.29767333e-04,\n",
      "        4.13076490e-05, -3.64234587e-04, -2.69264355e-04,  7.89203357e-05,\n",
      "       -9.02115629e-05, -5.85181438e-05,  1.14905082e-04, -7.32911449e-05,\n",
      "        1.18300514e-04, -2.70810011e-05, -1.17187207e-04,  5.46022697e-05,\n",
      "       -1.96268963e-04, -1.38127462e-04,  2.97959940e-04,  3.64553805e-04,\n",
      "        6.71244129e-05, -5.00347968e-05]), 2: array([-5.50202079e-04,  4.09545016e-03,  3.01478071e-05, -1.95658644e-04,\n",
      "       -2.94521344e-03,  8.94866680e-04,  2.82798399e-04,  3.02915160e-03,\n",
      "       -7.69962345e-04,  1.09678664e-04,  1.27961923e-03,  2.42388208e-04,\n",
      "        2.90154442e-04, -7.19235190e-04, -4.39423050e-04, -2.67177500e-04,\n",
      "       -6.71148254e-04, -1.10937201e-04,  3.04129432e-04, -6.81028359e-05,\n",
      "       -2.69816044e-04,  5.49967022e-04,  3.99816746e-04,  7.58602036e-05,\n",
      "       -4.29494752e-04, -3.57019430e-04,  4.50241002e-04,  5.10506047e-04,\n",
      "       -3.70371167e-04, -6.61198648e-04]), 3: array([-1.05132793e-03,  2.88124759e-03, -7.57694823e-04,  2.66804495e-04,\n",
      "       -2.06684738e-03,  1.01773974e-03,  1.48356295e-04,  1.39277768e-03,\n",
      "        1.09626442e-04,  7.40996362e-04,  1.29175443e-04,  4.49579579e-04,\n",
      "        4.81275512e-04, -4.98383982e-04, -7.15022547e-04, -5.34866053e-04,\n",
      "       -4.43782123e-04, -3.26645482e-04, -2.87379083e-04,  7.61867191e-05,\n",
      "       -4.94545985e-05,  3.66191417e-04,  3.56334135e-04, -2.09132137e-04,\n",
      "       -1.01458721e-04, -1.59688506e-04,  1.32285474e-04,  2.44846643e-05,\n",
      "       -8.89376096e-05, -3.90974188e-04])} {0: 2.70253565799824e-07, 1: 1.4153925867691526e-07, 2: 3.015008708280526e-07, 3: 1.0948146883388447e-07}\n",
      "found new domain 3 geb\n",
      "found new domain 3 geb\n",
      "found new domain 3 geb\n",
      "found new domain 3 geb\n",
      "found new domain 3 geb\n",
      "found new domain 3 geb\n",
      "found new domain 3 geb\n",
      "Epoch 0:  20%|██        | 125/616 [00:37<02:27,  3.33it/s, loss=0.0676, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "Epoch 0:  20%|██        | 126/616 [00:38<02:30,  3.26it/s, loss=0.0649, v_num=0]predicted domain -1\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "Epoch 0:  21%|██        | 127/616 [00:39<02:32,  3.20it/s, loss=0.0637, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "Epoch 0:  21%|██        | 128/616 [00:40<02:35,  3.14it/s, loss=0.062, v_num=0] predicted domain -1\n",
      "predicted domain 2\n",
      "predicted domain 3\n",
      "inserting sample geb\n",
      "predicted domain 2\n",
      "0.3434492610998295 3\n",
      "Epoch 0:  21%|██        | 129/616 [00:42<02:38,  3.07it/s, loss=0.0616, v_num=0]predicted domain 2\n",
      "predicted domain 3\n",
      "predicted domain 3\n",
      "predicted domain 2\n",
      "Epoch 0:  21%|██        | 130/616 [00:42<02:37,  3.08it/s, loss=0.0616, v_num=0]predicted domain 3\n",
      "predicted domain 3\n",
      "predicted domain 3\n",
      "predicted domain 2\n",
      "Epoch 0:  21%|██▏       | 131/616 [00:42<02:37,  3.08it/s, loss=0.0616, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 3\n",
      "predicted domain 2\n",
      "Epoch 0:  21%|██▏       | 132/616 [00:42<02:36,  3.09it/s, loss=0.0616, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "Epoch 0:  22%|██▏       | 133/616 [00:43<02:36,  3.09it/s, loss=0.0616, v_num=0]predicted domain 3\n",
      "predicted domain 3\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "Epoch 0:  22%|██▏       | 134/616 [00:43<02:35,  3.09it/s, loss=0.0616, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  22%|██▏       | 136/616 [00:43<02:34,  3.11it/s, loss=0.0616, v_num=0]\n",
      "Validating:   6%|▌         | 2/36 [00:00<00:12,  2.67it/s]\u001b[A\n",
      "Epoch 0:  22%|██▏       | 138/616 [00:44<02:33,  3.12it/s, loss=0.0616, v_num=0]\n",
      "Validating:  11%|█         | 4/36 [00:01<00:09,  3.36it/s]\u001b[A\n",
      "Epoch 0:  23%|██▎       | 140/616 [00:44<02:31,  3.14it/s, loss=0.0616, v_num=0]\n",
      "Validating:  17%|█▋        | 6/36 [00:01<00:07,  4.00it/s]\u001b[A\n",
      "Epoch 0:  23%|██▎       | 142/616 [00:45<02:30,  3.15it/s, loss=0.0616, v_num=0]\n",
      "Validating:  22%|██▏       | 8/36 [00:01<00:06,  4.44it/s]\u001b[A\n",
      "Epoch 0:  23%|██▎       | 144/616 [00:45<02:28,  3.17it/s, loss=0.0616, v_num=0]\n",
      "Validating:  28%|██▊       | 10/36 [00:02<00:05,  4.87it/s]\u001b[A\n",
      "Epoch 0:  24%|██▎       | 146/616 [00:45<02:27,  3.19it/s, loss=0.0616, v_num=0]\n",
      "Validating:  33%|███▎      | 12/36 [00:02<00:04,  5.07it/s]\u001b[A\n",
      "Epoch 0:  24%|██▍       | 148/616 [00:46<02:25,  3.21it/s, loss=0.0616, v_num=0]\n",
      "Validating:  39%|███▉      | 14/36 [00:03<00:04,  5.13it/s]\u001b[A\n",
      "Epoch 0:  24%|██▍       | 150/616 [00:46<02:24,  3.22it/s, loss=0.0616, v_num=0]\n",
      "Validating:  44%|████▍     | 16/36 [00:03<00:03,  5.21it/s]\u001b[A\n",
      "Epoch 0:  25%|██▍       | 152/616 [00:46<02:23,  3.24it/s, loss=0.0616, v_num=0]\n",
      "Validating:  50%|█████     | 18/36 [00:03<00:03,  5.31it/s]\u001b[A\n",
      "Epoch 0:  25%|██▌       | 154/616 [00:47<02:21,  3.26it/s, loss=0.0616, v_num=0]\n",
      "Validating:  56%|█████▌    | 20/36 [00:04<00:03,  5.18it/s]\u001b[A\n",
      "Epoch 0:  25%|██▌       | 156/616 [00:47<02:20,  3.27it/s, loss=0.0616, v_num=0]\n",
      "Validating:  61%|██████    | 22/36 [00:04<00:02,  5.13it/s]\u001b[A\n",
      "Epoch 0:  26%|██▌       | 158/616 [00:48<02:19,  3.29it/s, loss=0.0616, v_num=0]\n",
      "Validating:  67%|██████▋   | 24/36 [00:04<00:02,  5.19it/s]\u001b[A\n",
      "Epoch 0:  26%|██▌       | 160/616 [00:48<02:18,  3.30it/s, loss=0.0616, v_num=0]\n",
      "Validating:  72%|███████▏  | 26/36 [00:05<00:01,  5.06it/s]\u001b[A\n",
      "Epoch 0:  26%|██▋       | 162/616 [00:48<02:17,  3.31it/s, loss=0.0616, v_num=0]\n",
      "Validating:  78%|███████▊  | 28/36 [00:05<00:01,  5.16it/s]\u001b[A\n",
      "Epoch 0:  27%|██▋       | 164/616 [00:49<02:15,  3.33it/s, loss=0.0616, v_num=0]\n",
      "Validating:  83%|████████▎ | 30/36 [00:06<00:01,  5.23it/s]\u001b[A\n",
      "Epoch 0:  27%|██▋       | 166/616 [00:49<02:14,  3.34it/s, loss=0.0616, v_num=0]\n",
      "Validating:  89%|████████▉ | 32/36 [00:06<00:00,  5.23it/s]\u001b[A\n",
      "Epoch 0:  27%|██▋       | 168/616 [00:50<02:13,  3.36it/s, loss=0.0616, v_num=0]\n",
      "Validating:  94%|█████████▍| 34/36 [00:06<00:00,  5.32it/s]\u001b[A\n",
      "Epoch 0:  28%|██▊       | 171/616 [00:50<02:12,  3.36it/s, loss=0.0616, v_num=0]\n",
      "                                                           \u001b[Apredicted domain 3\n",
      "predicted domain -1\n",
      "predicted domain 2\n",
      "predicted domain 3\n",
      "Epoch 0:  28%|██▊       | 172/616 [00:51<02:12,  3.36it/s, loss=0.0616, v_num=0]predicted domain 3\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "Epoch 0:  28%|██▊       | 173/616 [00:51<02:11,  3.37it/s, loss=0.0616, v_num=0]predicted domain 2\n",
      "predicted domain 3\n",
      "predicted domain 3\n",
      "predicted domain 2\n",
      "Epoch 0:  28%|██▊       | 174/616 [00:51<02:10,  3.38it/s, loss=0.0616, v_num=0]predicted domain 2\n",
      "predicted domain 3\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "Epoch 0:  28%|██▊       | 175/616 [00:51<02:10,  3.38it/s, loss=0.0616, v_num=0]predicted domain 3\n",
      "predicted domain 2\n",
      "predicted domain 3\n",
      "predicted domain 2\n",
      "Epoch 0:  29%|██▊       | 176/616 [00:51<02:09,  3.39it/s, loss=0.0616, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "Epoch 0:  29%|██▊       | 177/616 [00:52<02:09,  3.40it/s, loss=0.0616, v_num=0]predicted domain 2\n",
      "predicted domain 3\n",
      "predicted domain 2\n",
      "predicted domain -1\n",
      "Epoch 0:  29%|██▉       | 178/616 [00:52<02:08,  3.40it/s, loss=0.0616, v_num=0]predicted domain 2\n",
      "predicted domain 3\n",
      "predicted domain 2\n",
      "predicted domain -1\n",
      "Epoch 0:  29%|██▉       | 179/616 [00:52<02:08,  3.41it/s, loss=0.0616, v_num=0]predicted domain 3\n",
      "predicted domain 2\n",
      "predicted domain 3\n",
      "predicted domain 3\n",
      "Epoch 0:  29%|██▉       | 180/616 [00:52<02:07,  3.41it/s, loss=0.0616, v_num=0]new shift to sie\n",
      "predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain 3\n",
      "predicted domain 2\n",
      "Epoch 0:  29%|██▉       | 181/616 [00:54<02:10,  3.32it/s, loss=0.0616, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 3\n",
      "predicted domain 3\n",
      "Epoch 0:  30%|██▉       | 182/616 [00:54<02:10,  3.33it/s, loss=0.0616, v_num=0]predicted domain -1\n",
      "predicted domain 2\n",
      "predicted domain 3\n",
      "predicted domain 2\n",
      "Epoch 0:  30%|██▉       | 183/616 [00:54<02:09,  3.33it/s, loss=0.0616, v_num=0]predicted domain 2\n",
      "predicted domain 0\n",
      "predicted domain 2\n",
      "predicted domain 3\n",
      "Epoch 0:  30%|██▉       | 184/616 [00:55<02:09,  3.34it/s, loss=0.0616, v_num=0]predicted domain 0\n",
      "predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain -1\n",
      "Epoch 0:  30%|███       | 185/616 [00:55<02:08,  3.34it/s, loss=0.0616, v_num=0]predicted domain -1\n",
      "predicted domain 2\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:  30%|███       | 186/616 [00:55<02:08,  3.35it/s, loss=0.0616, v_num=0]predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain 2\n",
      "Epoch 0:  30%|███       | 187/616 [00:55<02:07,  3.36it/s, loss=0.0616, v_num=0]predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain 2\n",
      "predicted domain -1\n",
      "outlier distance 0.034780458575122394\n",
      "Epoch 0:  31%|███       | 188/616 [00:55<02:07,  3.36it/s, loss=0.0616, v_num=0]predicted domain 2\n",
      "predicted domain 2\n",
      "predicted domain 3\n",
      "predicted domain 0\n",
      "outlier distance 0.04008251475951725\n",
      "Epoch 0:  31%|███       | 189/616 [00:56<02:06,  3.37it/s, loss=0.0616, v_num=0]predicted domain 2\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain 3\n",
      "outlier distance 0.027166128039023064\n",
      "Epoch 0:  31%|███       | 190/616 [00:56<02:06,  3.37it/s, loss=0.0616, v_num=0]predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "outlier distance 0.017001484962717646\n",
      "new center {0: array([ 3.85399991e-20, -3.81164826e-20,  0.00000000e+00,  3.64224167e-20,\n",
      "        4.40457133e-20, -4.44692297e-20,  3.49401091e-20, -2.10699446e-20,\n",
      "       -1.65171425e-20, -2.38492714e-20, -3.81164826e-21, -7.62329653e-21,\n",
      "        1.49355731e-20,  1.69406589e-21, -8.99972506e-21, -1.10114283e-20,\n",
      "       -2.51462906e-21,  4.34104385e-21, -6.14098887e-21, -1.79994501e-21,\n",
      "       -1.32348898e-21, -8.54312137e-21, -2.03287907e-20, -3.99693672e-21,\n",
      "        1.37642854e-21, -3.49401091e-21,  0.00000000e+00, -6.35274710e-21,\n",
      "       -9.21148330e-21, -2.75285708e-21]), 1: array([-4.31657144e-04,  2.33725901e-03, -7.66082792e-04, -8.21060711e-04,\n",
      "       -1.71836049e-03, -2.77380606e-04,  6.64274759e-04,  1.10728798e-03,\n",
      "       -4.40664459e-04, -6.20084145e-04,  7.88546783e-04,  2.29767333e-04,\n",
      "        4.13076490e-05, -3.64234587e-04, -2.69264355e-04,  7.89203357e-05,\n",
      "       -9.02115629e-05, -5.85181438e-05,  1.14905082e-04, -7.32911449e-05,\n",
      "        1.18300514e-04, -2.70810011e-05, -1.17187207e-04,  5.46022697e-05,\n",
      "       -1.96268963e-04, -1.38127462e-04,  2.97959940e-04,  3.64553805e-04,\n",
      "        6.71244129e-05, -5.00347968e-05]), 2: array([-5.50202079e-04,  4.09545016e-03,  3.01478071e-05, -1.95658644e-04,\n",
      "       -2.94521344e-03,  8.94866680e-04,  2.82798399e-04,  3.02915160e-03,\n",
      "       -7.69962345e-04,  1.09678664e-04,  1.27961923e-03,  2.42388208e-04,\n",
      "        2.90154442e-04, -7.19235190e-04, -4.39423050e-04, -2.67177500e-04,\n",
      "       -6.71148254e-04, -1.10937201e-04,  3.04129432e-04, -6.81028359e-05,\n",
      "       -2.69816044e-04,  5.49967022e-04,  3.99816746e-04,  7.58602036e-05,\n",
      "       -4.29494752e-04, -3.57019430e-04,  4.50241002e-04,  5.10506047e-04,\n",
      "       -3.70371167e-04, -6.61198648e-04]), 3: array([-1.13548800e-03,  2.87125399e-03, -7.55822372e-04,  2.79011588e-04,\n",
      "       -2.07639462e-03,  9.42811065e-04,  1.34637910e-04,  1.47710375e-03,\n",
      "        4.20760863e-05,  7.30389608e-04,  1.29478096e-04,  4.49607839e-04,\n",
      "        4.53734148e-04, -5.10826412e-04, -7.17896215e-04, -5.27962354e-04,\n",
      "       -4.53449829e-04, -3.35233956e-04, -2.71524663e-04,  5.98158103e-05,\n",
      "       -3.45253653e-05,  3.68757188e-04,  3.25339913e-04, -1.99880388e-04,\n",
      "       -1.28939863e-04, -1.56080242e-04,  1.38599402e-04,  3.93184798e-05,\n",
      "       -6.62055075e-05, -3.80579786e-04]), 4: array([-1.02214819e-03,  4.52697148e-04, -1.33214979e-03, -9.44972841e-04,\n",
      "       -1.48575386e-03, -7.26937869e-04,  1.46367915e-03,  1.70976667e-04,\n",
      "       -8.47777295e-05, -3.15549148e-04,  3.67438513e-04,  1.86184783e-04,\n",
      "        3.53014429e-04, -2.54552482e-04,  8.35987647e-05,  5.21939845e-04,\n",
      "       -7.49011736e-05,  4.21095789e-05, -7.39570244e-06,  1.10458550e-05,\n",
      "        2.36158547e-05, -1.82798502e-04, -2.80544695e-04,  8.60920136e-06,\n",
      "       -9.38762698e-05, -1.86789355e-04,  3.81899483e-05,  2.52919767e-04,\n",
      "       -4.77582534e-05,  8.70479672e-05])} {0: 2.70253565799824e-07, 1: 1.4153925867691526e-07, 2: 3.015008708280526e-07, 3: 1.0960960892845809e-07, 4: 1.0672022221708158e-07}\n",
      "found new domain 4 sie\n",
      "found new domain 4 sie\n",
      "found new domain 4 sie\n",
      "found new domain 4 sie\n",
      "found new domain 4 sie\n",
      "found new domain 4 sie\n",
      "found new domain 4 sie\n",
      "found new domain 4 sie\n",
      "found new domain 4 sie\n",
      "found new domain 4 sie\n",
      "0.3142151876465651 4\n",
      "Epoch 0:  31%|███       | 192/616 [00:57<02:07,  3.32it/s, loss=0.0711, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/36 [00:00<00:15,  2.20it/s]\u001b[A\n",
      "Epoch 0:  31%|███▏      | 194/616 [00:58<02:07,  3.31it/s, loss=0.0711, v_num=0]\n",
      "Validating:   8%|▊         | 3/36 [00:00<00:10,  3.11it/s]\u001b[A\n",
      "Epoch 0:  32%|███▏      | 196/616 [00:58<02:06,  3.33it/s, loss=0.0711, v_num=0]\n",
      "Validating:  14%|█▍        | 5/36 [00:01<00:07,  3.91it/s]\u001b[A\n",
      "Epoch 0:  32%|███▏      | 198/616 [00:59<02:05,  3.34it/s, loss=0.0711, v_num=0]\n",
      "Validating:  19%|█▉        | 7/36 [00:01<00:06,  4.45it/s]\u001b[A\n",
      "Epoch 0:  32%|███▏      | 200/616 [00:59<02:04,  3.35it/s, loss=0.0711, v_num=0]\n",
      "Validating:  25%|██▌       | 9/36 [00:01<00:05,  4.79it/s]\u001b[A\n",
      "Epoch 0:  33%|███▎      | 202/616 [01:00<02:03,  3.36it/s, loss=0.0711, v_num=0]\n",
      "Validating:  31%|███       | 11/36 [00:02<00:04,  5.04it/s]\u001b[A\n",
      "Epoch 0:  33%|███▎      | 204/616 [01:00<02:02,  3.37it/s, loss=0.0711, v_num=0]\n",
      "Validating:  36%|███▌      | 13/36 [00:02<00:04,  5.11it/s]\u001b[A\n",
      "Epoch 0:  33%|███▎      | 206/616 [01:00<02:01,  3.38it/s, loss=0.0711, v_num=0]\n",
      "Validating:  42%|████▏     | 15/36 [00:03<00:04,  4.85it/s]\u001b[A\n",
      "Epoch 0:  34%|███▍      | 208/616 [01:01<02:00,  3.39it/s, loss=0.0711, v_num=0]\n",
      "Validating:  47%|████▋     | 17/36 [00:03<00:03,  5.11it/s]\u001b[A\n",
      "Epoch 0:  34%|███▍      | 210/616 [01:01<01:59,  3.41it/s, loss=0.0711, v_num=0]\n",
      "Validating:  53%|█████▎    | 19/36 [00:03<00:03,  4.92it/s]\u001b[A\n",
      "Epoch 0:  34%|███▍      | 212/616 [01:02<01:58,  3.41it/s, loss=0.0711, v_num=0]\n",
      "Validating:  58%|█████▊    | 21/36 [00:04<00:03,  4.90it/s]\u001b[A\n",
      "Epoch 0:  35%|███▍      | 214/616 [01:02<01:57,  3.42it/s, loss=0.0711, v_num=0]\n",
      "Validating:  64%|██████▍   | 23/36 [00:04<00:02,  5.01it/s]\u001b[A\n",
      "Epoch 0:  35%|███▌      | 216/616 [01:02<01:56,  3.43it/s, loss=0.0711, v_num=0]\n",
      "Validating:  69%|██████▉   | 25/36 [00:05<00:02,  4.75it/s]\u001b[A\n",
      "Epoch 0:  35%|███▌      | 218/616 [01:03<01:55,  3.44it/s, loss=0.0711, v_num=0]\n",
      "Validating:  75%|███████▌  | 27/36 [00:05<00:01,  4.98it/s]\u001b[A\n",
      "Epoch 0:  36%|███▌      | 220/616 [01:03<01:54,  3.45it/s, loss=0.0711, v_num=0]\n",
      "Validating:  81%|████████  | 29/36 [00:05<00:01,  5.07it/s]\u001b[A\n",
      "Epoch 0:  36%|███▌      | 222/616 [01:04<01:53,  3.46it/s, loss=0.0711, v_num=0]\n",
      "Validating:  86%|████████▌ | 31/36 [00:06<00:00,  5.24it/s]\u001b[A\n",
      "Epoch 0:  36%|███▋      | 224/616 [01:04<01:52,  3.48it/s, loss=0.0711, v_num=0]\n",
      "Validating:  92%|█████████▏| 33/36 [00:06<00:00,  5.36it/s]\u001b[A\n",
      "Epoch 0:  37%|███▋      | 226/616 [01:04<01:51,  3.49it/s, loss=0.0711, v_num=0]\n",
      "Epoch 0:  37%|███▋      | 228/616 [01:05<01:51,  3.48it/s, loss=0.0711, v_num=0]\n",
      "                                                           \u001b[Apredicted domain 0\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "Epoch 0:  37%|███▋      | 229/616 [01:05<01:51,  3.48it/s, loss=0.0711, v_num=0]predicted domain 4\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "predicted domain 0\n",
      "Epoch 0:  37%|███▋      | 230/616 [01:05<01:50,  3.49it/s, loss=0.0711, v_num=0]predicted domain -1\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "Epoch 0:  38%|███▊      | 231/616 [01:06<01:50,  3.49it/s, loss=0.0711, v_num=0]predicted domain 0\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "predicted domain -1\n",
      "Epoch 0:  38%|███▊      | 232/616 [01:06<01:49,  3.49it/s, loss=0.0711, v_num=0]predicted domain 4\n",
      "predicted domain 0\n",
      "predicted domain 4\n",
      "predicted domain 0\n",
      "Epoch 0:  38%|███▊      | 233/616 [01:06<01:49,  3.50it/s, loss=0.0711, v_num=0]predicted domain 4\n",
      "predicted domain -1\n",
      "predicted domain 0\n",
      "predicted domain 4\n",
      "Epoch 0:  38%|███▊      | 234/616 [01:06<01:49,  3.50it/s, loss=0.0711, v_num=0]predicted domain 0\n",
      "predicted domain 4\n",
      "predicted domain 0\n",
      "predicted domain 4\n",
      "Epoch 0:  38%|███▊      | 235/616 [01:07<01:48,  3.51it/s, loss=0.0711, v_num=0]predicted domain 4\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "predicted domain 0\n",
      "Epoch 0:  38%|███▊      | 236/616 [01:07<01:48,  3.51it/s, loss=0.0711, v_num=0]predicted domain 4\n",
      "predicted domain 4\n",
      "predicted domain 1\n",
      "predicted domain -1\n",
      "Epoch 0:  38%|███▊      | 237/616 [01:07<01:47,  3.51it/s, loss=0.0711, v_num=0]predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "Epoch 0:  39%|███▊      | 238/616 [01:07<01:47,  3.52it/s, loss=0.0711, v_num=0]predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain 4\n",
      "predicted domain 0\n",
      "Epoch 0:  39%|███▉      | 239/616 [01:07<01:47,  3.52it/s, loss=0.0711, v_num=0]predicted domain 4\n",
      "predicted domain 4\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "Epoch 0:  39%|███▉      | 240/616 [01:08<01:46,  3.53it/s, loss=0.0711, v_num=0]predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "Epoch 0:  39%|███▉      | 241/616 [01:08<01:46,  3.53it/s, loss=0.0711, v_num=0]predicted domain 4\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "Epoch 0:  39%|███▉      | 242/616 [01:08<01:45,  3.53it/s, loss=0.0711, v_num=0]predicted domain 0\n",
      "predicted domain 1\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "Epoch 0:  39%|███▉      | 243/616 [01:08<01:45,  3.54it/s, loss=0.0711, v_num=0]predicted domain 0\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "predicted domain 0\n",
      "Epoch 0:  40%|███▉      | 244/616 [01:08<01:45,  3.54it/s, loss=0.0711, v_num=0]predicted domain 4\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain 4\n",
      "outlier distance 0.03002601073037414\n",
      "Epoch 0:  40%|███▉      | 245/616 [01:09<01:44,  3.54it/s, loss=0.0711, v_num=0]new shift to lndb\n",
      "predicted domain 4\n",
      "predicted domain -1\n",
      "predicted domain 4\n",
      "predicted domain 4\n",
      "outlier distance 0.02770965162360221\n",
      "Epoch 0:  40%|███▉      | 246/616 [01:10<01:46,  3.47it/s, loss=0.0711, v_num=0]predicted domain 0\n",
      "predicted domain 4\n",
      "predicted domain -1\n",
      "predicted domain 4\n",
      "outlier distance 0.027264666539540187\n",
      "Epoch 0:  40%|████      | 247/616 [01:11<01:46,  3.47it/s, loss=0.0711, v_num=0]predicted domain 4\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 4\n",
      "outlier distance 0.02861829023528383\n",
      "Epoch 0:  40%|████      | 248/616 [01:11<01:45,  3.48it/s, loss=0.0711, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  41%|████      | 250/616 [01:12<01:45,  3.47it/s, loss=0.0711, v_num=0]\n",
      "Validating:   6%|▌         | 2/36 [00:00<00:13,  2.52it/s]\u001b[A\n",
      "Epoch 0:  41%|████      | 252/616 [01:12<01:44,  3.48it/s, loss=0.0711, v_num=0]\n",
      "Validating:  11%|█         | 4/36 [00:01<00:09,  3.29it/s]\u001b[A\n",
      "Epoch 0:  41%|████      | 254/616 [01:12<01:43,  3.49it/s, loss=0.0711, v_num=0]\n",
      "Validating:  17%|█▋        | 6/36 [00:01<00:07,  4.05it/s]\u001b[A\n",
      "Epoch 0:  42%|████▏     | 256/616 [01:13<01:42,  3.50it/s, loss=0.0711, v_num=0]\n",
      "Validating:  22%|██▏       | 8/36 [00:01<00:06,  4.57it/s]\u001b[A\n",
      "Epoch 0:  42%|████▏     | 258/616 [01:13<01:42,  3.50it/s, loss=0.0711, v_num=0]\n",
      "Validating:  28%|██▊       | 10/36 [00:02<00:06,  4.15it/s]\u001b[A\n",
      "Epoch 0:  42%|████▏     | 260/616 [01:14<01:41,  3.51it/s, loss=0.0711, v_num=0]\n",
      "Validating:  33%|███▎      | 12/36 [00:02<00:05,  4.39it/s]\u001b[A\n",
      "Epoch 0:  43%|████▎     | 262/616 [01:14<01:40,  3.51it/s, loss=0.0711, v_num=0]\n",
      "Validating:  39%|███▉      | 14/36 [00:03<00:04,  4.77it/s]\u001b[A\n",
      "Epoch 0:  43%|████▎     | 264/616 [01:14<01:39,  3.52it/s, loss=0.0711, v_num=0]\n",
      "Validating:  44%|████▍     | 16/36 [00:03<00:04,  4.83it/s]\u001b[A\n",
      "Epoch 0:  43%|████▎     | 266/616 [01:15<01:39,  3.53it/s, loss=0.0711, v_num=0]\n",
      "Validating:  50%|█████     | 18/36 [00:04<00:03,  4.93it/s]\u001b[A\n",
      "Epoch 0:  44%|████▎     | 268/616 [01:15<01:38,  3.54it/s, loss=0.0711, v_num=0]\n",
      "Validating:  56%|█████▌    | 20/36 [00:04<00:03,  4.69it/s]\u001b[A\n",
      "Epoch 0:  44%|████▍     | 270/616 [01:16<01:37,  3.54it/s, loss=0.0711, v_num=0]\n",
      "Validating:  61%|██████    | 22/36 [00:04<00:02,  4.69it/s]\u001b[A\n",
      "Epoch 0:  44%|████▍     | 272/616 [01:16<01:36,  3.55it/s, loss=0.0711, v_num=0]\n",
      "Validating:  67%|██████▋   | 24/36 [00:05<00:02,  4.63it/s]\u001b[A\n",
      "Epoch 0:  44%|████▍     | 274/616 [01:17<01:36,  3.55it/s, loss=0.0711, v_num=0]\n",
      "Validating:  72%|███████▏  | 26/36 [00:05<00:02,  4.35it/s]\u001b[A\n",
      "Epoch 0:  45%|████▍     | 276/616 [01:17<01:35,  3.56it/s, loss=0.0711, v_num=0]\n",
      "Validating:  78%|███████▊  | 28/36 [00:06<00:01,  4.35it/s]\u001b[A\n",
      "Epoch 0:  45%|████▌     | 278/616 [01:18<01:34,  3.56it/s, loss=0.0711, v_num=0]\n",
      "Validating:  83%|████████▎ | 30/36 [00:06<00:01,  4.37it/s]\u001b[A\n",
      "Epoch 0:  45%|████▌     | 280/616 [01:18<01:34,  3.57it/s, loss=0.0711, v_num=0]\n",
      "Validating:  89%|████████▉ | 32/36 [00:07<00:00,  4.60it/s]\u001b[A\n",
      "Epoch 0:  46%|████▌     | 282/616 [01:18<01:33,  3.57it/s, loss=0.0711, v_num=0]\n",
      "Validating:  94%|█████████▍| 34/36 [00:07<00:00,  4.87it/s]\u001b[A\n",
      "Epoch 0:  46%|████▋     | 285/616 [01:19<01:32,  3.57it/s, loss=0.0711, v_num=0]\n",
      "                                                           \u001b[Apredicted domain 2\n",
      "predicted domain 0\n",
      "predicted domain 0\n",
      "predicted domain 1\n",
      "outlier distance 0.03141790563910573\n",
      "Epoch 0:  46%|████▋     | 286/616 [01:20<01:32,  3.57it/s, loss=0.0711, v_num=0]predicted domain -1\n",
      "predicted domain 4\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "outlier distance 0.026228317680075088\n",
      "Epoch 0:  47%|████▋     | 287/616 [01:20<01:31,  3.58it/s, loss=0.0711, v_num=0]predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "outlier distance 0.02194043561664586\n",
      "new center {0: array([ 3.85399991e-20, -3.81164826e-20,  0.00000000e+00,  3.64224167e-20,\n",
      "        4.40457133e-20, -4.44692297e-20,  3.49401091e-20, -2.10699446e-20,\n",
      "       -1.65171425e-20, -2.38492714e-20, -3.81164826e-21, -7.62329653e-21,\n",
      "        1.49355731e-20,  1.69406589e-21, -8.99972506e-21, -1.10114283e-20,\n",
      "       -2.51462906e-21,  4.34104385e-21, -6.14098887e-21, -1.79994501e-21,\n",
      "       -1.32348898e-21, -8.54312137e-21, -2.03287907e-20, -3.99693672e-21,\n",
      "        1.37642854e-21, -3.49401091e-21,  0.00000000e+00, -6.35274710e-21,\n",
      "       -9.21148330e-21, -2.75285708e-21]), 1: array([-4.31657144e-04,  2.33725901e-03, -7.66082792e-04, -8.21060711e-04,\n",
      "       -1.71836049e-03, -2.77380606e-04,  6.64274759e-04,  1.10728798e-03,\n",
      "       -4.40664459e-04, -6.20084145e-04,  7.88546783e-04,  2.29767333e-04,\n",
      "        4.13076490e-05, -3.64234587e-04, -2.69264355e-04,  7.89203357e-05,\n",
      "       -9.02115629e-05, -5.85181438e-05,  1.14905082e-04, -7.32911449e-05,\n",
      "        1.18300514e-04, -2.70810011e-05, -1.17187207e-04,  5.46022697e-05,\n",
      "       -1.96268963e-04, -1.38127462e-04,  2.97959940e-04,  3.64553805e-04,\n",
      "        6.71244129e-05, -5.00347968e-05]), 2: array([-5.50202079e-04,  4.09545016e-03,  3.01478071e-05, -1.95658644e-04,\n",
      "       -2.94521344e-03,  8.94866680e-04,  2.82798399e-04,  3.02915160e-03,\n",
      "       -7.69962345e-04,  1.09678664e-04,  1.27961923e-03,  2.42388208e-04,\n",
      "        2.90154442e-04, -7.19235190e-04, -4.39423050e-04, -2.67177500e-04,\n",
      "       -6.71148254e-04, -1.10937201e-04,  3.04129432e-04, -6.81028359e-05,\n",
      "       -2.69816044e-04,  5.49967022e-04,  3.99816746e-04,  7.58602036e-05,\n",
      "       -4.29494752e-04, -3.57019430e-04,  4.50241002e-04,  5.10506047e-04,\n",
      "       -3.70371167e-04, -6.61198648e-04]), 3: array([-1.13548800e-03,  2.87125399e-03, -7.55822372e-04,  2.79011588e-04,\n",
      "       -2.07639462e-03,  9.42811065e-04,  1.34637910e-04,  1.47710375e-03,\n",
      "        4.20760863e-05,  7.30389608e-04,  1.29478096e-04,  4.49607839e-04,\n",
      "        4.53734148e-04, -5.10826412e-04, -7.17896215e-04, -5.27962354e-04,\n",
      "       -4.53449829e-04, -3.35233956e-04, -2.71524663e-04,  5.98158103e-05,\n",
      "       -3.45253653e-05,  3.68757188e-04,  3.25339913e-04, -1.99880388e-04,\n",
      "       -1.28939863e-04, -1.56080242e-04,  1.38599402e-04,  3.93184798e-05,\n",
      "       -6.62055075e-05, -3.80579786e-04]), 4: array([-1.02214819e-03,  4.52697148e-04, -1.33214979e-03, -9.44972841e-04,\n",
      "       -1.48575386e-03, -7.26937869e-04,  1.46367915e-03,  1.70976667e-04,\n",
      "       -8.47777295e-05, -3.15549148e-04,  3.67438513e-04,  1.86184783e-04,\n",
      "        3.53014429e-04, -2.54552482e-04,  8.35987647e-05,  5.21939845e-04,\n",
      "       -7.49011736e-05,  4.21095789e-05, -7.39570244e-06,  1.10458550e-05,\n",
      "        2.36158547e-05, -1.82798502e-04, -2.80544695e-04,  8.60920136e-06,\n",
      "       -9.38762698e-05, -1.86789355e-04,  3.81899483e-05,  2.52919767e-04,\n",
      "       -4.77582534e-05,  8.70479672e-05]), 5: array([-9.79321188e-04,  1.93907575e-03, -9.88687256e-04, -7.07586848e-04,\n",
      "       -2.48616527e-03,  5.53994773e-04,  1.43330713e-03,  9.15273696e-04,\n",
      "        1.61635131e-04, -2.09499890e-04,  6.49703657e-04,  3.70811151e-04,\n",
      "        4.25974472e-04, -5.56022396e-04,  9.43620428e-05,  4.09118482e-04,\n",
      "       -2.15876442e-04,  1.51855653e-04, -1.04299196e-04, -4.18921153e-05,\n",
      "       -1.06287187e-04,  6.56030055e-05, -8.29060266e-05, -3.20056308e-04,\n",
      "       -8.58624914e-05, -2.60857482e-04,  3.56841886e-04,  2.39778896e-04,\n",
      "       -1.24339658e-04, -2.38389323e-04])} {0: 2.70253565799824e-07, 1: 1.4153925867691526e-07, 2: 3.015008708280526e-07, 3: 1.0960960892845809e-07, 4: 1.0672022221708158e-07, 5: 2.308280620078315e-07}\n",
      "found new domain 5 sie\n",
      "found new domain 5 sie\n",
      "found new domain 5 lndb\n",
      "found new domain 5 lndb\n",
      "found new domain 5 lndb\n",
      "found new domain 5 lndb\n",
      "found new domain 5 lndb\n",
      "found new domain 5 lndb\n",
      "found new domain 5 lndb\n",
      "found new domain 5 lndb\n",
      "found new domain 5 lndb\n",
      "0.07557990401983261 5\n",
      "Epoch 0:  47%|████▋     | 288/616 [01:21<01:33,  3.51it/s, loss=0.0696, v_num=0]predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.17356696724891663 5\n",
      "Epoch 0:  47%|████▋     | 289/616 [01:23<01:34,  3.47it/s, loss=0.0722, v_num=0]predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.09798706322908401 5\n",
      "Epoch 0:  47%|████▋     | 290/616 [01:24<01:35,  3.43it/s, loss=0.0779, v_num=0]predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.1898188367486 5\n",
      "Epoch 0:  47%|████▋     | 291/616 [01:25<01:35,  3.39it/s, loss=0.0846, v_num=0]predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.09183177351951599 5\n",
      "Epoch 0:  47%|████▋     | 292/616 [01:27<01:36,  3.36it/s, loss=0.0867, v_num=0]predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.11519776927484779 5\n",
      "Epoch 0:  48%|████▊     | 293/616 [01:28<01:37,  3.32it/s, loss=0.0854, v_num=0]predicted domain 2\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.11519776927484779 5\n",
      "Epoch 0:  48%|████▊     | 294/616 [01:29<01:38,  3.28it/s, loss=0.0853, v_num=0]predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.0511881097981302 5\n",
      "Epoch 0:  48%|████▊     | 295/616 [01:30<01:38,  3.24it/s, loss=0.0849, v_num=0]predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.0 5\n",
      "Epoch 0:  48%|████▊     | 296/616 [01:32<01:39,  3.21it/s, loss=0.0888, v_num=0]predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.1134049863332801 5\n",
      "Epoch 0:  48%|████▊     | 297/616 [01:33<01:40,  3.17it/s, loss=0.0952, v_num=0]predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.1134049863332801 5\n",
      "Epoch 0:  48%|████▊     | 298/616 [01:34<01:41,  3.14it/s, loss=0.0932, v_num=0]predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.10768833197653294 5\n",
      "Epoch 0:  49%|████▊     | 299/616 [01:36<01:41,  3.11it/s, loss=0.117, v_num=0] predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.10768833197653294 5\n",
      "Epoch 0:  49%|████▊     | 300/616 [01:37<01:42,  3.08it/s, loss=0.121, v_num=0]predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain -1\n",
      "0.16400529723614454 5\n",
      "Epoch 0:  49%|████▉     | 301/616 [01:38<01:43,  3.06it/s, loss=0.12, v_num=0] predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.1608739550322577 5\n",
      "Epoch 0:  49%|████▉     | 302/616 [01:39<01:43,  3.03it/s, loss=0.124, v_num=0]predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "0.18685548557939974 5\n",
      "Epoch 0:  49%|████▉     | 303/616 [01:41<01:44,  3.00it/s, loss=0.127, v_num=0]predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 0\n",
      "0.13769487469497171 5\n",
      "Epoch 0:  49%|████▉     | 304/616 [01:42<01:45,  2.97it/s, loss=0.133, v_num=0]predicted domain -1\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 2\n",
      "predicted domain -1\n",
      "outlier distance 0.02644925249727549\n",
      "0.18520348195065367 5\n",
      "Epoch 0:  50%|████▉     | 306/616 [01:43<01:44,  2.96it/s, loss=0.134, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/36 [00:00<00:16,  2.15it/s]\u001b[A\n",
      "Epoch 0:  50%|█████     | 308/616 [01:44<01:44,  2.96it/s, loss=0.134, v_num=0]\n",
      "Validating:   8%|▊         | 3/36 [00:00<00:10,  3.05it/s]\u001b[A\n",
      "Epoch 0:  50%|█████     | 310/616 [01:44<01:43,  2.97it/s, loss=0.134, v_num=0]\n",
      "Validating:  14%|█▍        | 5/36 [00:01<00:07,  3.90it/s]\u001b[A\n",
      "Epoch 0:  51%|█████     | 312/616 [01:44<01:42,  2.97it/s, loss=0.134, v_num=0]\n",
      "Validating:  19%|█▉        | 7/36 [00:01<00:06,  4.45it/s]\u001b[A\n",
      "Epoch 0:  51%|█████     | 314/616 [01:45<01:41,  2.98it/s, loss=0.134, v_num=0]\n",
      "Validating:  25%|██▌       | 9/36 [00:02<00:05,  4.71it/s]\u001b[A\n",
      "Epoch 0:  51%|█████▏    | 316/616 [01:45<01:40,  2.99it/s, loss=0.134, v_num=0]\n",
      "Validating:  31%|███       | 11/36 [00:02<00:05,  4.78it/s]\u001b[A\n",
      "Epoch 0:  52%|█████▏    | 318/616 [01:46<01:39,  3.00it/s, loss=0.134, v_num=0]\n",
      "Validating:  36%|███▌      | 13/36 [00:02<00:04,  4.86it/s]\u001b[A\n",
      "Epoch 0:  52%|█████▏    | 320/616 [01:46<01:38,  3.00it/s, loss=0.134, v_num=0]\n",
      "Validating:  42%|████▏     | 15/36 [00:03<00:04,  4.70it/s]\u001b[A\n",
      "Epoch 0:  52%|█████▏    | 322/616 [01:47<01:37,  3.01it/s, loss=0.134, v_num=0]\n",
      "Validating:  47%|████▋     | 17/36 [00:03<00:04,  4.70it/s]\u001b[A\n",
      "Epoch 0:  53%|█████▎    | 324/616 [01:47<01:36,  3.02it/s, loss=0.134, v_num=0]\n",
      "Validating:  53%|█████▎    | 19/36 [00:04<00:03,  4.86it/s]\u001b[A\n",
      "Epoch 0:  53%|█████▎    | 326/616 [01:47<01:35,  3.02it/s, loss=0.134, v_num=0]\n",
      "Validating:  58%|█████▊    | 21/36 [00:04<00:03,  4.97it/s]\u001b[A\n",
      "Epoch 0:  53%|█████▎    | 328/616 [01:48<01:34,  3.03it/s, loss=0.134, v_num=0]\n",
      "Validating:  64%|██████▍   | 23/36 [00:04<00:02,  5.02it/s]\u001b[A\n",
      "Epoch 0:  54%|█████▎    | 330/616 [01:48<01:34,  3.04it/s, loss=0.134, v_num=0]\n",
      "Validating:  69%|██████▉   | 25/36 [00:05<00:02,  5.09it/s]\u001b[A\n",
      "Epoch 0:  54%|█████▍    | 332/616 [01:48<01:33,  3.05it/s, loss=0.134, v_num=0]\n",
      "Validating:  75%|███████▌  | 27/36 [00:05<00:01,  5.14it/s]\u001b[A\n",
      "Epoch 0:  54%|█████▍    | 334/616 [01:49<01:32,  3.05it/s, loss=0.134, v_num=0]\n",
      "Validating:  81%|████████  | 29/36 [00:06<00:01,  4.83it/s]\u001b[A\n",
      "Epoch 0:  55%|█████▍    | 336/616 [01:49<01:31,  3.06it/s, loss=0.134, v_num=0]\n",
      "Validating:  86%|████████▌ | 31/36 [00:06<00:01,  4.90it/s]\u001b[A\n",
      "Epoch 0:  55%|█████▍    | 338/616 [01:50<01:30,  3.07it/s, loss=0.134, v_num=0]\n",
      "Validating:  92%|█████████▏| 33/36 [00:06<00:00,  4.80it/s]\u001b[A\n",
      "Epoch 0:  55%|█████▌    | 340/616 [01:50<01:29,  3.07it/s, loss=0.134, v_num=0]\n",
      "Epoch 0:  56%|█████▌    | 342/616 [01:51<01:29,  3.06it/s, loss=0.134, v_num=0]\n",
      "                                                           \u001b[Apredicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "inserting sample lndb\n",
      "outlier distance 0.030228864185958777\n",
      "0.3619439823131608 5\n",
      "Epoch 0:  56%|█████▌    | 343/616 [01:53<01:30,  3.03it/s, loss=0.138, v_num=0]predicted domain -1\n",
      "predicted domain 5\n",
      "predicted domain 2\n",
      "predicted domain 5\n",
      "outlier distance 0.027536348994508495\n",
      "Epoch 0:  56%|█████▌    | 344/616 [01:53<01:29,  3.03it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  56%|█████▌    | 345/616 [01:53<01:29,  3.03it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  56%|█████▌    | 346/616 [01:53<01:28,  3.04it/s, loss=0.138, v_num=0]predicted domain -1\n",
      "predicted domain 5\n",
      "predicted domain 2\n",
      "predicted domain 5\n",
      "Epoch 0:  56%|█████▋    | 347/616 [01:54<01:28,  3.04it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 1\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "outlier distance 0.034625614204620576\n",
      "Epoch 0:  56%|█████▋    | 348/616 [01:54<01:28,  3.04it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 2\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "outlier distance 0.034625614204620576\n",
      "Epoch 0:  57%|█████▋    | 349/616 [01:54<01:27,  3.05it/s, loss=0.138, v_num=0]predicted domain 2\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 4\n",
      "outlier distance 0.030431570946545056\n",
      "Epoch 0:  57%|█████▋    | 350/616 [01:54<01:27,  3.05it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "outlier distance 0.030527737032180452\n",
      "Epoch 0:  57%|█████▋    | 351/616 [01:54<01:26,  3.05it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "outlier distance 0.0331810171332723\n",
      "Epoch 0:  57%|█████▋    | 352/616 [01:55<01:26,  3.06it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "outlier distance 0.0331810171332723\n",
      "Epoch 0:  57%|█████▋    | 353/616 [01:55<01:25,  3.06it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 2\n",
      "predicted domain 5\n",
      "Epoch 0:  57%|█████▋    | 354/616 [01:55<01:25,  3.06it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "Epoch 0:  58%|█████▊    | 355/616 [01:55<01:25,  3.07it/s, loss=0.138, v_num=0]predicted domain -1\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  58%|█████▊    | 356/616 [01:56<01:24,  3.07it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  58%|█████▊    | 357/616 [01:56<01:24,  3.07it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  58%|█████▊    | 358/616 [01:56<01:23,  3.07it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  58%|█████▊    | 359/616 [01:56<01:23,  3.08it/s, loss=0.138, v_num=0]predicted domain -1\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  58%|█████▊    | 360/616 [01:56<01:23,  3.08it/s, loss=0.138, v_num=0]predicted domain -1\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  59%|█████▊    | 361/616 [01:57<01:22,  3.08it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  59%|█████▉    | 362/616 [01:57<01:22,  3.08it/s, loss=0.138, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 364/616 [01:57<01:21,  3.09it/s, loss=0.138, v_num=0]\n",
      "Validating:   6%|▌         | 2/36 [00:00<00:12,  2.75it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 366/616 [01:58<01:20,  3.10it/s, loss=0.138, v_num=0]\n",
      "Validating:  11%|█         | 4/36 [00:01<00:09,  3.51it/s]\u001b[A\n",
      "Epoch 0:  60%|█████▉    | 368/616 [01:58<01:19,  3.10it/s, loss=0.138, v_num=0]\n",
      "Validating:  17%|█▋        | 6/36 [00:01<00:07,  4.13it/s]\u001b[A\n",
      "Epoch 0:  60%|██████    | 370/616 [01:59<01:19,  3.11it/s, loss=0.138, v_num=0]\n",
      "Validating:  22%|██▏       | 8/36 [00:01<00:06,  4.51it/s]\u001b[A\n",
      "Epoch 0:  60%|██████    | 372/616 [01:59<01:18,  3.12it/s, loss=0.138, v_num=0]\n",
      "Validating:  28%|██▊       | 10/36 [00:02<00:05,  4.88it/s]\u001b[A\n",
      "Epoch 0:  61%|██████    | 374/616 [01:59<01:17,  3.12it/s, loss=0.138, v_num=0]\n",
      "Validating:  33%|███▎      | 12/36 [00:02<00:04,  4.92it/s]\u001b[A\n",
      "Epoch 0:  61%|██████    | 376/616 [02:00<01:16,  3.13it/s, loss=0.138, v_num=0]\n",
      "Validating:  39%|███▉      | 14/36 [00:03<00:04,  5.07it/s]\u001b[A\n",
      "Epoch 0:  61%|██████▏   | 378/616 [02:00<01:15,  3.13it/s, loss=0.138, v_num=0]\n",
      "Validating:  44%|████▍     | 16/36 [00:03<00:03,  5.14it/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 380/616 [02:00<01:15,  3.14it/s, loss=0.138, v_num=0]\n",
      "Validating:  50%|█████     | 18/36 [00:03<00:03,  5.02it/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 382/616 [02:01<01:14,  3.15it/s, loss=0.138, v_num=0]\n",
      "Validating:  56%|█████▌    | 20/36 [00:04<00:03,  5.10it/s]\u001b[A\n",
      "Epoch 0:  62%|██████▏   | 384/616 [02:01<01:13,  3.15it/s, loss=0.138, v_num=0]\n",
      "Validating:  61%|██████    | 22/36 [00:04<00:02,  5.11it/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 386/616 [02:02<01:12,  3.16it/s, loss=0.138, v_num=0]\n",
      "Validating:  67%|██████▋   | 24/36 [00:04<00:02,  5.09it/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 388/616 [02:02<01:12,  3.17it/s, loss=0.138, v_num=0]\n",
      "Validating:  72%|███████▏  | 26/36 [00:05<00:01,  5.15it/s]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 390/616 [02:02<01:11,  3.17it/s, loss=0.138, v_num=0]\n",
      "Validating:  78%|███████▊  | 28/36 [00:05<00:01,  5.11it/s]\u001b[A\n",
      "Epoch 0:  64%|██████▎   | 392/616 [02:03<01:10,  3.18it/s, loss=0.138, v_num=0]\n",
      "Validating:  83%|████████▎ | 30/36 [00:06<00:01,  5.15it/s]\u001b[A\n",
      "Epoch 0:  64%|██████▍   | 394/616 [02:03<01:09,  3.18it/s, loss=0.138, v_num=0]\n",
      "Validating:  89%|████████▉ | 32/36 [00:06<00:00,  5.14it/s]\u001b[A\n",
      "Epoch 0:  64%|██████▍   | 396/616 [02:04<01:08,  3.19it/s, loss=0.138, v_num=0]\n",
      "Validating:  94%|█████████▍| 34/36 [00:06<00:00,  4.89it/s]\u001b[A\n",
      "Epoch 0:  65%|██████▍   | 399/616 [02:05<01:08,  3.19it/s, loss=0.138, v_num=0]\n",
      "                                                           \u001b[Apredicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "Epoch 0:  65%|██████▍   | 400/616 [02:05<01:07,  3.19it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 2\n",
      "predicted domain 5\n",
      "Epoch 0:  65%|██████▌   | 401/616 [02:05<01:07,  3.19it/s, loss=0.138, v_num=0]predicted domain -1\n",
      "predicted domain 5\n",
      "predicted domain 2\n",
      "predicted domain 5\n",
      "Epoch 0:  65%|██████▌   | 402/616 [02:05<01:07,  3.19it/s, loss=0.138, v_num=0]predicted domain -1\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "outlier distance 0.03329523336567785\n",
      "Epoch 0:  65%|██████▌   | 403/616 [02:06<01:06,  3.20it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "outlier distance 0.032571654204219085\n",
      "Epoch 0:  66%|██████▌   | 404/616 [02:06<01:06,  3.20it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 0\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "outlier distance 0.030911844003170263\n",
      "Epoch 0:  66%|██████▌   | 405/616 [02:06<01:05,  3.20it/s, loss=0.138, v_num=0]predicted domain 2\n",
      "predicted domain 5\n",
      "predicted domain 3\n",
      "predicted domain 2\n",
      "outlier distance 0.030911844003170263\n",
      "Epoch 0:  66%|██████▌   | 406/616 [02:06<01:05,  3.20it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "outlier distance 0.030911844003170263\n",
      "Epoch 0:  66%|██████▌   | 407/616 [02:06<01:05,  3.21it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 2\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "outlier distance 0.030911844003170263\n",
      "Epoch 0:  66%|██████▌   | 408/616 [02:07<01:04,  3.21it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "outlier distance 0.029126359115744828\n",
      "Epoch 0:  66%|██████▋   | 409/616 [02:07<01:04,  3.21it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "outlier distance 0.0310637120272376\n",
      "Epoch 0:  67%|██████▋   | 410/616 [02:07<01:04,  3.21it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "outlier distance 0.028088601723414597\n",
      "Epoch 0:  67%|██████▋   | 411/616 [02:07<01:03,  3.21it/s, loss=0.138, v_num=0]predicted domain 2\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "outlier distance 0.024409928806433813\n",
      "new center {0: array([ 3.85399991e-20, -3.81164826e-20,  0.00000000e+00,  3.64224167e-20,\n",
      "        4.40457133e-20, -4.44692297e-20,  3.49401091e-20, -2.10699446e-20,\n",
      "       -1.65171425e-20, -2.38492714e-20, -3.81164826e-21, -7.62329653e-21,\n",
      "        1.49355731e-20,  1.69406589e-21, -8.99972506e-21, -1.10114283e-20,\n",
      "       -2.51462906e-21,  4.34104385e-21, -6.14098887e-21, -1.79994501e-21,\n",
      "       -1.32348898e-21, -8.54312137e-21, -2.03287907e-20, -3.99693672e-21,\n",
      "        1.37642854e-21, -3.49401091e-21,  0.00000000e+00, -6.35274710e-21,\n",
      "       -9.21148330e-21, -2.75285708e-21]), 1: array([-4.31657144e-04,  2.33725901e-03, -7.66082792e-04, -8.21060711e-04,\n",
      "       -1.71836049e-03, -2.77380606e-04,  6.64274759e-04,  1.10728798e-03,\n",
      "       -4.40664459e-04, -6.20084145e-04,  7.88546783e-04,  2.29767333e-04,\n",
      "        4.13076490e-05, -3.64234587e-04, -2.69264355e-04,  7.89203357e-05,\n",
      "       -9.02115629e-05, -5.85181438e-05,  1.14905082e-04, -7.32911449e-05,\n",
      "        1.18300514e-04, -2.70810011e-05, -1.17187207e-04,  5.46022697e-05,\n",
      "       -1.96268963e-04, -1.38127462e-04,  2.97959940e-04,  3.64553805e-04,\n",
      "        6.71244129e-05, -5.00347968e-05]), 2: array([-5.50202079e-04,  4.09545016e-03,  3.01478071e-05, -1.95658644e-04,\n",
      "       -2.94521344e-03,  8.94866680e-04,  2.82798399e-04,  3.02915160e-03,\n",
      "       -7.69962345e-04,  1.09678664e-04,  1.27961923e-03,  2.42388208e-04,\n",
      "        2.90154442e-04, -7.19235190e-04, -4.39423050e-04, -2.67177500e-04,\n",
      "       -6.71148254e-04, -1.10937201e-04,  3.04129432e-04, -6.81028359e-05,\n",
      "       -2.69816044e-04,  5.49967022e-04,  3.99816746e-04,  7.58602036e-05,\n",
      "       -4.29494752e-04, -3.57019430e-04,  4.50241002e-04,  5.10506047e-04,\n",
      "       -3.70371167e-04, -6.61198648e-04]), 3: array([-1.13548800e-03,  2.87125399e-03, -7.55822372e-04,  2.79011588e-04,\n",
      "       -2.07639462e-03,  9.42811065e-04,  1.34637910e-04,  1.47710375e-03,\n",
      "        4.20760863e-05,  7.30389608e-04,  1.29478096e-04,  4.49607839e-04,\n",
      "        4.53734148e-04, -5.10826412e-04, -7.17896215e-04, -5.27962354e-04,\n",
      "       -4.53449829e-04, -3.35233956e-04, -2.71524663e-04,  5.98158103e-05,\n",
      "       -3.45253653e-05,  3.68757188e-04,  3.25339913e-04, -1.99880388e-04,\n",
      "       -1.28939863e-04, -1.56080242e-04,  1.38599402e-04,  3.93184798e-05,\n",
      "       -6.62055075e-05, -3.80579786e-04]), 4: array([-1.02214819e-03,  4.52697148e-04, -1.33214979e-03, -9.44972841e-04,\n",
      "       -1.48575386e-03, -7.26937869e-04,  1.46367915e-03,  1.70976667e-04,\n",
      "       -8.47777295e-05, -3.15549148e-04,  3.67438513e-04,  1.86184783e-04,\n",
      "        3.53014429e-04, -2.54552482e-04,  8.35987647e-05,  5.21939845e-04,\n",
      "       -7.49011736e-05,  4.21095789e-05, -7.39570244e-06,  1.10458550e-05,\n",
      "        2.36158547e-05, -1.82798502e-04, -2.80544695e-04,  8.60920136e-06,\n",
      "       -9.38762698e-05, -1.86789355e-04,  3.81899483e-05,  2.52919767e-04,\n",
      "       -4.77582534e-05,  8.70479672e-05]), 5: array([-1.20351807e-03,  2.11632526e-03, -7.89467762e-04, -4.12684785e-04,\n",
      "       -2.73336638e-03,  8.77317921e-04,  1.30254096e-03,  1.20368530e-03,\n",
      "        1.19753511e-04, -1.22323182e-04,  6.93914797e-04,  3.46630754e-04,\n",
      "        4.89988474e-04, -6.00739039e-04,  9.10095234e-05,  3.79004849e-04,\n",
      "       -2.55212361e-04,  2.10086344e-04, -7.09531883e-05, -1.38038815e-04,\n",
      "       -1.28346908e-04,  1.02917934e-04, -7.37586828e-05, -2.77327978e-04,\n",
      "       -1.77550576e-04, -2.57268642e-04,  3.90917121e-04,  2.06507429e-04,\n",
      "       -1.35544242e-04, -3.54220409e-04]), 6: array([ 3.62953474e-04,  3.14431480e-03, -8.54198285e-04, -7.39074416e-04,\n",
      "       -2.91908611e-03,  6.07138682e-04,  2.05671041e-03,  1.29854708e-03,\n",
      "        8.92431633e-05, -1.01370564e-03,  1.08127772e-03,  9.61613534e-04,\n",
      "        1.19815829e-03, -1.01515282e-03,  4.24923770e-04,  2.17922844e-04,\n",
      "       -4.73481842e-04,  5.28442471e-04,  1.93370112e-05, -1.33143442e-04,\n",
      "       -2.78502534e-04,  1.95914232e-04,  2.05722903e-04, -3.49895215e-04,\n",
      "       -2.61997789e-04, -3.30646860e-04,  5.61414565e-04,  6.24500465e-04,\n",
      "       -3.42555912e-04, -4.06406047e-04])} {0: 2.70253565799824e-07, 1: 1.4153925867691526e-07, 2: 3.015008708280526e-07, 3: 1.0960960892845809e-07, 4: 1.0672022221708158e-07, 5: 1.8152595752678923e-07, 6: 1.4420824769853877e-07}\n",
      "found new domain 6 lndb\n",
      "found new domain 6 lndb\n",
      "found new domain 6 lndb\n",
      "found new domain 6 lndb\n",
      "found new domain 6 lndb\n",
      "found new domain 6 lndb\n",
      "Epoch 0:  67%|██████▋   | 412/616 [02:09<01:04,  3.19it/s, loss=0.133, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  67%|██████▋   | 413/616 [02:10<01:04,  3.17it/s, loss=0.137, v_num=0]predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 0\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  67%|██████▋   | 414/616 [02:11<01:04,  3.15it/s, loss=0.15, v_num=0] predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  67%|██████▋   | 415/616 [02:12<01:04,  3.13it/s, loss=0.161, v_num=0]predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "0.09238807018846273 6\n",
      "Epoch 0:  68%|██████▊   | 416/616 [02:13<01:04,  3.11it/s, loss=0.162, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 3\n",
      "0.09238807018846273 6\n",
      "Epoch 0:  68%|██████▊   | 417/616 [02:14<01:04,  3.09it/s, loss=0.164, v_num=0]predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.09238807018846273 6\n",
      "Epoch 0:  68%|██████▊   | 418/616 [02:15<01:04,  3.08it/s, loss=0.174, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.09238807018846273 6\n",
      "Epoch 0:  68%|██████▊   | 420/616 [02:17<01:03,  3.06it/s, loss=0.176, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/36 [00:00<00:16,  2.09it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▊   | 422/616 [02:17<01:03,  3.06it/s, loss=0.176, v_num=0]\n",
      "Validating:   8%|▊         | 3/36 [00:00<00:11,  2.95it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▉   | 424/616 [02:18<01:02,  3.07it/s, loss=0.176, v_num=0]\n",
      "Validating:  14%|█▍        | 5/36 [00:01<00:08,  3.77it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▉   | 426/616 [02:18<01:01,  3.07it/s, loss=0.176, v_num=0]\n",
      "Validating:  19%|█▉        | 7/36 [00:01<00:06,  4.23it/s]\u001b[A\n",
      "Epoch 0:  69%|██████▉   | 428/616 [02:18<01:01,  3.08it/s, loss=0.176, v_num=0]\n",
      "Validating:  25%|██▌       | 9/36 [00:02<00:05,  4.62it/s]\u001b[A\n",
      "Epoch 0:  70%|██████▉   | 430/616 [02:19<01:00,  3.09it/s, loss=0.176, v_num=0]\n",
      "Validating:  31%|███       | 11/36 [00:02<00:05,  4.90it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 432/616 [02:19<00:59,  3.09it/s, loss=0.176, v_num=0]\n",
      "Validating:  36%|███▌      | 13/36 [00:02<00:04,  4.70it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 434/616 [02:20<00:58,  3.10it/s, loss=0.176, v_num=0]\n",
      "Validating:  42%|████▏     | 15/36 [00:03<00:04,  4.69it/s]\u001b[A\n",
      "Epoch 0:  71%|███████   | 436/616 [02:20<00:58,  3.10it/s, loss=0.176, v_num=0]\n",
      "Validating:  47%|████▋     | 17/36 [00:03<00:03,  4.77it/s]\u001b[A\n",
      "Epoch 0:  71%|███████   | 438/616 [02:21<00:57,  3.11it/s, loss=0.176, v_num=0]\n",
      "Validating:  53%|█████▎    | 19/36 [00:04<00:03,  4.93it/s]\u001b[A\n",
      "Epoch 0:  71%|███████▏  | 440/616 [02:21<00:56,  3.11it/s, loss=0.176, v_num=0]\n",
      "Validating:  58%|█████▊    | 21/36 [00:04<00:02,  5.01it/s]\u001b[A\n",
      "Epoch 0:  72%|███████▏  | 442/616 [02:21<00:55,  3.12it/s, loss=0.176, v_num=0]\n",
      "Validating:  64%|██████▍   | 23/36 [00:04<00:02,  4.81it/s]\u001b[A\n",
      "Epoch 0:  72%|███████▏  | 444/616 [02:22<00:55,  3.12it/s, loss=0.176, v_num=0]\n",
      "Validating:  69%|██████▉   | 25/36 [00:05<00:02,  4.65it/s]\u001b[A\n",
      "Epoch 0:  72%|███████▏  | 446/616 [02:22<00:54,  3.13it/s, loss=0.176, v_num=0]\n",
      "Validating:  75%|███████▌  | 27/36 [00:05<00:01,  4.85it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 448/616 [02:23<00:53,  3.13it/s, loss=0.176, v_num=0]\n",
      "Validating:  81%|████████  | 29/36 [00:06<00:01,  4.95it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 450/616 [02:23<00:52,  3.14it/s, loss=0.176, v_num=0]\n",
      "Validating:  86%|████████▌ | 31/36 [00:06<00:01,  4.93it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 452/616 [02:23<00:52,  3.14it/s, loss=0.176, v_num=0]\n",
      "Validating:  92%|█████████▏| 33/36 [00:07<00:00,  4.86it/s]\u001b[A\n",
      "Epoch 0:  74%|███████▎  | 454/616 [02:24<00:51,  3.15it/s, loss=0.176, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 456/616 [02:25<00:50,  3.14it/s, loss=0.176, v_num=0]\n",
      "                                                           \u001b[Apredicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "0.06999996583908796 6\n",
      "Epoch 0:  74%|███████▍  | 457/616 [02:26<00:50,  3.12it/s, loss=0.179, v_num=0]predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.12870997842401266 6\n",
      "Epoch 0:  74%|███████▍  | 458/616 [02:27<00:50,  3.10it/s, loss=0.179, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.12870997842401266 6\n",
      "Epoch 0:  75%|███████▍  | 459/616 [02:28<00:50,  3.08it/s, loss=0.177, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.12870997842401266 6\n",
      "Epoch 0:  75%|███████▍  | 460/616 [02:30<00:50,  3.07it/s, loss=0.18, v_num=0] predicted domain 2\n",
      "predicted domain 4\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.12870997842401266 6\n",
      "Epoch 0:  75%|███████▍  | 461/616 [02:31<00:50,  3.05it/s, loss=0.161, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.12870997842401266 6\n",
      "Epoch 0:  75%|███████▌  | 462/616 [02:32<00:50,  3.03it/s, loss=0.162, v_num=0]predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "0.19579961895942688 6\n",
      "Epoch 0:  75%|███████▌  | 463/616 [02:33<00:50,  3.02it/s, loss=0.163, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.19579961895942688 6\n",
      "Epoch 0:  75%|███████▌  | 464/616 [02:34<00:50,  3.00it/s, loss=0.162, v_num=0]predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.19579961895942688 6\n",
      "Epoch 0:  75%|███████▌  | 465/616 [02:35<00:50,  2.98it/s, loss=0.162, v_num=0]predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.19579961895942688 6\n",
      "Epoch 0:  76%|███████▌  | 466/616 [02:37<00:50,  2.97it/s, loss=0.157, v_num=0]predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 2\n",
      "predicted domain 5\n",
      "0.19579961895942688 6\n",
      "Epoch 0:  76%|███████▌  | 467/616 [02:38<00:50,  2.95it/s, loss=0.158, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "0.13778618350625038 6\n",
      "Epoch 0:  76%|███████▌  | 468/616 [02:39<00:50,  2.93it/s, loss=0.158, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.13778618350625038 6\n",
      "Epoch 0:  76%|███████▌  | 469/616 [02:40<00:50,  2.92it/s, loss=0.159, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.13778618350625038 6\n",
      "Epoch 0:  76%|███████▋  | 470/616 [02:41<00:50,  2.90it/s, loss=0.158, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain -1\n",
      "0.13778618350625038 6\n",
      "Epoch 0:  76%|███████▋  | 471/616 [02:42<00:50,  2.89it/s, loss=0.146, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.13778618350625038 6\n",
      "Epoch 0:  77%|███████▋  | 472/616 [02:44<00:50,  2.88it/s, loss=0.132, v_num=0]predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain -1\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "0.1142713725566864 6\n",
      "Epoch 0:  77%|███████▋  | 473/616 [02:45<00:50,  2.86it/s, loss=0.143, v_num=0]predicted domain 2\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "0.03519520163536072 6\n",
      "Epoch 0:  77%|███████▋  | 474/616 [02:46<00:49,  2.84it/s, loss=0.14, v_num=0] predicted domain -1\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "0.03519520163536072 6\n",
      "Epoch 0:  77%|███████▋  | 475/616 [02:47<00:49,  2.83it/s, loss=0.134, v_num=0]predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "0.03519520163536072 6\n",
      "Epoch 0:  77%|███████▋  | 476/616 [02:49<00:49,  2.82it/s, loss=0.136, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 478/616 [02:49<00:48,  2.82it/s, loss=0.136, v_num=0]\n",
      "Validating:   6%|▌         | 2/36 [00:00<00:13,  2.56it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 480/616 [02:49<00:48,  2.82it/s, loss=0.136, v_num=0]\n",
      "Validating:  11%|█         | 4/36 [00:01<00:09,  3.31it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 482/616 [02:50<00:47,  2.83it/s, loss=0.136, v_num=0]\n",
      "Validating:  17%|█▋        | 6/36 [00:01<00:07,  3.91it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▊  | 484/616 [02:50<00:46,  2.83it/s, loss=0.136, v_num=0]\n",
      "Validating:  22%|██▏       | 8/36 [00:01<00:06,  4.33it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▉  | 486/616 [02:51<00:45,  2.84it/s, loss=0.136, v_num=0]\n",
      "Validating:  28%|██▊       | 10/36 [00:02<00:05,  4.66it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▉  | 488/616 [02:51<00:45,  2.84it/s, loss=0.136, v_num=0]\n",
      "Validating:  33%|███▎      | 12/36 [00:02<00:04,  4.89it/s]\u001b[A\n",
      "Epoch 0:  80%|███████▉  | 490/616 [02:51<00:44,  2.85it/s, loss=0.136, v_num=0]\n",
      "Validating:  39%|███▉      | 14/36 [00:03<00:04,  4.88it/s]\u001b[A\n",
      "Epoch 0:  80%|███████▉  | 492/616 [02:52<00:43,  2.85it/s, loss=0.136, v_num=0]\n",
      "Validating:  44%|████▍     | 16/36 [00:03<00:04,  4.85it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 494/616 [02:52<00:42,  2.86it/s, loss=0.136, v_num=0]\n",
      "Validating:  50%|█████     | 18/36 [00:03<00:03,  4.94it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 496/616 [02:53<00:41,  2.86it/s, loss=0.136, v_num=0]\n",
      "Validating:  56%|█████▌    | 20/36 [00:04<00:03,  4.84it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 498/616 [02:53<00:41,  2.87it/s, loss=0.136, v_num=0]\n",
      "Validating:  61%|██████    | 22/36 [00:04<00:02,  4.92it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 500/616 [02:54<00:40,  2.87it/s, loss=0.136, v_num=0]\n",
      "Validating:  67%|██████▋   | 24/36 [00:05<00:02,  4.81it/s]\u001b[A\n",
      "Epoch 0:  81%|████████▏ | 502/616 [02:54<00:39,  2.88it/s, loss=0.136, v_num=0]\n",
      "Validating:  72%|███████▏  | 26/36 [00:05<00:02,  4.93it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 504/616 [02:54<00:38,  2.88it/s, loss=0.136, v_num=0]\n",
      "Validating:  78%|███████▊  | 28/36 [00:05<00:01,  5.06it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 506/616 [02:55<00:38,  2.89it/s, loss=0.136, v_num=0]\n",
      "Validating:  83%|████████▎ | 30/36 [00:06<00:01,  5.08it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 508/616 [02:55<00:37,  2.89it/s, loss=0.136, v_num=0]\n",
      "Validating:  89%|████████▉ | 32/36 [00:06<00:00,  4.95it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 510/616 [02:56<00:36,  2.90it/s, loss=0.136, v_num=0]\n",
      "Validating:  94%|█████████▍| 34/36 [00:07<00:00,  5.01it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 513/616 [02:57<00:35,  2.90it/s, loss=0.136, v_num=0]\n",
      "                                                           \u001b[Apredicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "0.03519520163536072 6\n",
      "Epoch 0:  83%|████████▎ | 514/616 [02:58<00:35,  2.88it/s, loss=0.135, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "0.03519520163536072 6\n",
      "Epoch 0:  84%|████████▎ | 515/616 [02:59<00:35,  2.87it/s, loss=0.134, v_num=0]predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "0.0 6\n",
      "Epoch 0:  84%|████████▍ | 516/616 [03:00<00:35,  2.85it/s, loss=0.134, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "0.05660990998148918 6\n",
      "Epoch 0:  84%|████████▍ | 517/616 [03:01<00:34,  2.84it/s, loss=0.133, v_num=0]predicted domain 0\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "0.05660990998148918 6\n",
      "Epoch 0:  84%|████████▍ | 518/616 [03:03<00:34,  2.83it/s, loss=0.13, v_num=0] predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "0.05660990998148918 6\n",
      "Epoch 0:  84%|████████▍ | 519/616 [03:04<00:34,  2.82it/s, loss=0.127, v_num=0]predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.05660990998148918 6\n",
      "Epoch 0:  84%|████████▍ | 520/616 [03:05<00:34,  2.80it/s, loss=0.126, v_num=0]predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "0.05660990998148918 6\n",
      "Epoch 0:  85%|████████▍ | 521/616 [03:06<00:34,  2.79it/s, loss=0.125, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.05660990998148918 6\n",
      "Epoch 0:  85%|████████▍ | 522/616 [03:07<00:33,  2.78it/s, loss=0.123, v_num=0]predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "0.11654080983417106 6\n",
      "Epoch 0:  85%|████████▍ | 523/616 [03:09<00:33,  2.77it/s, loss=0.124, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.11654080983417106 6\n",
      "Epoch 0:  85%|████████▌ | 524/616 [03:10<00:33,  2.75it/s, loss=0.125, v_num=0]predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "0.08041462648825717 6\n",
      "Epoch 0:  85%|████████▌ | 525/616 [03:11<00:33,  2.74it/s, loss=0.126, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.08041462648825717 6\n",
      "Epoch 0:  85%|████████▌ | 526/616 [03:12<00:32,  2.73it/s, loss=0.128, v_num=0]predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.1243278903158195 6\n",
      "Epoch 0:  86%|████████▌ | 527/616 [03:13<00:32,  2.72it/s, loss=0.125, v_num=0]predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "0.1243278903158195 6\n",
      "Epoch 0:  86%|████████▌ | 528/616 [03:14<00:32,  2.71it/s, loss=0.127, v_num=0]predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.13465600621121002 6\n",
      "Epoch 0:  86%|████████▌ | 529/616 [03:16<00:32,  2.70it/s, loss=0.138, v_num=0]predicted domain -1\n",
      "predicted domain 5\n",
      "predicted domain 1\n",
      "predicted domain 0\n",
      "0.13465600621121002 6\n",
      "Epoch 0:  86%|████████▌ | 530/616 [03:17<00:32,  2.69it/s, loss=0.122, v_num=0]predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "0.23454122245311737 6\n",
      "Epoch 0:  86%|████████▌ | 531/616 [03:18<00:31,  2.67it/s, loss=0.14, v_num=0] predicted domain -1\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain -1\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "0.21405749581754208 6\n",
      "Epoch 0:  86%|████████▋ | 532/616 [03:19<00:31,  2.66it/s, loss=0.137, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "0.17014423198997974 6\n",
      "Epoch 0:  87%|████████▋ | 534/616 [03:21<00:30,  2.66it/s, loss=0.133, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/36 [00:00<00:15,  2.30it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 536/616 [03:21<00:30,  2.66it/s, loss=0.133, v_num=0]\n",
      "Validating:   8%|▊         | 3/36 [00:00<00:10,  3.18it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 538/616 [03:22<00:29,  2.66it/s, loss=0.133, v_num=0]\n",
      "Validating:  14%|█▍        | 5/36 [00:01<00:07,  3.95it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 540/616 [03:22<00:28,  2.67it/s, loss=0.133, v_num=0]\n",
      "Validating:  19%|█▉        | 7/36 [00:01<00:06,  4.40it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 542/616 [03:22<00:27,  2.67it/s, loss=0.133, v_num=0]\n",
      "Validating:  25%|██▌       | 9/36 [00:02<00:05,  4.72it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 544/616 [03:23<00:26,  2.68it/s, loss=0.133, v_num=0]\n",
      "Validating:  31%|███       | 11/36 [00:02<00:04,  5.02it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▊ | 546/616 [03:23<00:26,  2.68it/s, loss=0.133, v_num=0]\n",
      "Validating:  36%|███▌      | 13/36 [00:02<00:04,  5.14it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 548/616 [03:24<00:25,  2.69it/s, loss=0.133, v_num=0]\n",
      "Validating:  42%|████▏     | 15/36 [00:03<00:04,  5.11it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 550/616 [03:24<00:24,  2.69it/s, loss=0.133, v_num=0]\n",
      "Validating:  47%|████▋     | 17/36 [00:03<00:03,  5.04it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 552/616 [03:24<00:23,  2.69it/s, loss=0.133, v_num=0]\n",
      "Validating:  53%|█████▎    | 19/36 [00:03<00:03,  5.00it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 554/616 [03:25<00:22,  2.70it/s, loss=0.133, v_num=0]\n",
      "Validating:  58%|█████▊    | 21/36 [00:04<00:03,  4.74it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 556/616 [03:25<00:22,  2.70it/s, loss=0.133, v_num=0]\n",
      "Validating:  64%|██████▍   | 23/36 [00:04<00:02,  4.88it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 558/616 [03:26<00:21,  2.71it/s, loss=0.133, v_num=0]\n",
      "Validating:  69%|██████▉   | 25/36 [00:05<00:02,  4.73it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 560/616 [03:26<00:20,  2.71it/s, loss=0.133, v_num=0]\n",
      "Validating:  75%|███████▌  | 27/36 [00:05<00:01,  4.80it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 562/616 [03:26<00:19,  2.72it/s, loss=0.133, v_num=0]\n",
      "Validating:  81%|████████  | 29/36 [00:06<00:01,  4.92it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 564/616 [03:27<00:19,  2.72it/s, loss=0.133, v_num=0]\n",
      "Validating:  86%|████████▌ | 31/36 [00:06<00:01,  4.94it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 566/616 [03:27<00:18,  2.72it/s, loss=0.133, v_num=0]\n",
      "Validating:  92%|█████████▏| 33/36 [00:06<00:00,  4.97it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 568/616 [03:28<00:17,  2.73it/s, loss=0.133, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 570/616 [03:29<00:16,  2.72it/s, loss=0.133, v_num=0]\n",
      "                                                           \u001b[Apredicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "0.26927694864571095 6\n",
      "Epoch 0:  93%|█████████▎| 571/616 [03:30<00:16,  2.71it/s, loss=0.138, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "predicted domain 6\n",
      "inserting sample lndb\n",
      "0.33525287359952927 6\n",
      "Epoch 0:  93%|█████████▎| 572/616 [03:31<00:16,  2.70it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  93%|█████████▎| 573/616 [03:31<00:15,  2.70it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  93%|█████████▎| 574/616 [03:32<00:15,  2.71it/s, loss=0.136, v_num=0]predicted domain -1\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "predicted domain 6\n",
      "Epoch 0:  93%|█████████▎| 575/616 [03:32<00:15,  2.71it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "predicted domain 5\n",
      "Epoch 0:  94%|█████████▎| 576/616 [03:32<00:14,  2.71it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  94%|█████████▎| 577/616 [03:32<00:14,  2.71it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain 6\n",
      "predicted domain 4\n",
      "predicted domain 5\n",
      "Epoch 0:  94%|█████████▍| 578/616 [03:33<00:14,  2.71it/s, loss=0.136, v_num=0]predicted domain 6\n",
      "predicted domain 6\n",
      "predicted domain -1\n",
      "predicted domain -1\n",
      "Epoch 0:  94%|█████████▍| 579/616 [03:33<00:13,  2.71it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  94%|█████████▍| 580/616 [03:33<00:13,  2.72it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "predicted domain 5\n",
      "Epoch 0:  94%|█████████▍| 581/616 [03:33<00:12,  2.72it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "Epoch 0:  94%|█████████▍| 582/616 [03:33<00:12,  2.72it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain 6\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  95%|█████████▍| 583/616 [03:34<00:12,  2.72it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "Epoch 0:  95%|█████████▍| 584/616 [03:34<00:11,  2.72it/s, loss=0.136, v_num=0]predicted domain 6\n",
      "predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "Epoch 0:  95%|█████████▍| 585/616 [03:34<00:11,  2.73it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "Epoch 0:  95%|█████████▌| 586/616 [03:34<00:10,  2.73it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "predicted domain -1\n",
      "Epoch 0:  95%|█████████▌| 587/616 [03:34<00:10,  2.73it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  95%|█████████▌| 588/616 [03:35<00:10,  2.73it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "predicted domain 5\n",
      "Epoch 0:  96%|█████████▌| 589/616 [03:35<00:09,  2.73it/s, loss=0.136, v_num=0]predicted domain 5\n",
      "predicted domain -1\n",
      "predicted domain 5\n",
      "predicted domain 6\n",
      "Epoch 0:  96%|█████████▌| 590/616 [03:35<00:09,  2.73it/s, loss=0.136, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 592/616 [03:36<00:08,  2.74it/s, loss=0.136, v_num=0]\n",
      "Validating:   6%|▌         | 2/36 [00:00<00:12,  2.71it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 594/616 [03:36<00:08,  2.74it/s, loss=0.136, v_num=0]\n",
      "Validating:  11%|█         | 4/36 [00:01<00:09,  3.50it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 596/616 [03:37<00:07,  2.75it/s, loss=0.136, v_num=0]\n",
      "Validating:  17%|█▋        | 6/36 [00:01<00:07,  4.07it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 598/616 [03:37<00:06,  2.75it/s, loss=0.136, v_num=0]\n",
      "Validating:  22%|██▏       | 8/36 [00:01<00:06,  4.49it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 600/616 [03:37<00:05,  2.75it/s, loss=0.136, v_num=0]\n",
      "Validating:  28%|██▊       | 10/36 [00:02<00:05,  4.80it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 602/616 [03:38<00:05,  2.76it/s, loss=0.136, v_num=0]\n",
      "Validating:  33%|███▎      | 12/36 [00:02<00:04,  4.92it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 604/616 [03:38<00:04,  2.76it/s, loss=0.136, v_num=0]\n",
      "Validating:  39%|███▉      | 14/36 [00:03<00:04,  4.80it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 606/616 [03:39<00:03,  2.77it/s, loss=0.136, v_num=0]\n",
      "Validating:  44%|████▍     | 16/36 [00:03<00:04,  4.97it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▊| 608/616 [03:39<00:02,  2.77it/s, loss=0.136, v_num=0]\n",
      "Validating:  50%|█████     | 18/36 [00:03<00:03,  5.12it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 610/616 [03:39<00:02,  2.78it/s, loss=0.136, v_num=0]\n",
      "Validating:  56%|█████▌    | 20/36 [00:04<00:03,  5.06it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 612/616 [03:40<00:01,  2.78it/s, loss=0.136, v_num=0]\n",
      "Validating:  61%|██████    | 22/36 [00:04<00:02,  4.82it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 614/616 [03:40<00:00,  2.78it/s, loss=0.136, v_num=0]\n",
      "Validating:  67%|██████▋   | 24/36 [00:05<00:02,  4.78it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 616/616 [03:41<00:00,  2.79it/s, loss=0.136, v_num=0]\n",
      "Validating:  72%|███████▏  | 26/36 [00:05<00:02,  4.91it/s]\u001b[A\n",
      "Validating:  75%|███████▌  | 27/36 [00:05<00:01,  4.91it/s]\u001b[A\n",
      "Validating:  78%|███████▊  | 28/36 [00:05<00:01,  5.00it/s]\u001b[A\n",
      "Validating:  81%|████████  | 29/36 [00:06<00:01,  5.00it/s]\u001b[A\n",
      "Validating:  83%|████████▎ | 30/36 [00:06<00:01,  5.08it/s]\u001b[A\n",
      "Validating:  86%|████████▌ | 31/36 [00:06<00:00,  5.14it/s]\u001b[A\n",
      "Validating:  89%|████████▉ | 32/36 [00:06<00:00,  5.07it/s]\u001b[A\n",
      "Validating:  92%|█████████▏| 33/36 [00:06<00:00,  5.09it/s]\u001b[A\n",
      "Validating:  94%|█████████▍| 34/36 [00:07<00:00,  5.08it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 616/616 [03:43<00:00,  2.75it/s, loss=0.136, v_num=0]\n",
      "Epoch 0: 100%|██████████| 616/616 [03:44<00:00,  2.75it/s, loss=0.136, v_num=0]\n",
      "train counter 81\n",
      "label counter 167\n",
      "True True\n",
      "successfully trained model lidc_cont_lungnodulesfinallndbBig_basemodel_batch_memory_tf08_1_9cf36c6c67.pt\n"
     ]
    }
   ],
   "source": [
    "train_config('training_configs/lidc_casa.yml', remote=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/project/catinous/lungnodulesfinallndbBig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>bin_malignancy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th>scanner</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <th>ges</th>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">test</th>\n",
       "      <th>geb</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ges</th>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lndb</th>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sie</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">train</th>\n",
       "      <th>geb</th>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ges</th>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lndb</th>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sie</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">val</th>\n",
       "      <th>geb</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ges</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lndb</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sie</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset  patient_id  image   x1   x2   y1   y2  bin_malignancy\n",
       "split scanner                                                                \n",
       "base  ges          253         253    253  253  253  253  253             253\n",
       "test  geb           26          26     26   26   26   26   26              26\n",
       "      ges           85          85     85   85   85   85   85              85\n",
       "      lndb          91          91     91   91   91   91   91              91\n",
       "      sie           18          18     18   18   18   18   18              18\n",
       "train geb          166         166    166  166  166  166  166             166\n",
       "      ges          136         136    136  136  136  136  136             136\n",
       "      lndb         479         479    479  479  479  479  479             479\n",
       "      sie          102         102    102  102  102  102  102             102\n",
       "val   geb           23          23     23   23   23   23   23              23\n",
       "      ges           53          53     53   53   53   53   53              53\n",
       "      lndb          55          55     55   55   55   55   55              55\n",
       "      sie           10          10     10   10   10   10   10              10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['split', 'scanner']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176.6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "883/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from datasets.BrainAgeContinuous import BrainAgeContinuous\n",
    "#from datasets.BrainAgeDataset import BrainAgeDataset\n",
    "#from datasets.CatsinomDataset import CatsinomDataset\n",
    "#from datasets.LIDCDataset import LIDCDataset\n",
    "from models.unet3d import EncoderModelGenesis\n",
    "import torchvision.models as tvmodels\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "#from statsmodels.distributions.empirical_distribution import ECDF\n",
    "#import statsmodels.api as sm\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scipy.stats import gaussian_kde, norm, multivariate_normal\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "import torch.nn as nn\n",
    "\n",
    "#from statsmodels.nonparametric.kernel_density import KDEMultivariate\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy.spatial.distance import seuclidean, euclidean, mahalanobis, pdist, squareform\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "import active_dynamicmemory.utils as cutils\n",
    "import pickle\n",
    "from datasets.BatchDataset import CardiacBatch\n",
    "from active_dynamicmemory.ActiveDynamicMemory import MemoryItem\n",
    "from datasets.ContinuousDataset import CardiacContinuous\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(input):\n",
    "    # taken from: https://pytorch.org/tutorials/advanced/neural_style_tutorial.html\n",
    "    a, b, c, d = input.size()  # a=batch size(=1)\n",
    "    # b=number of feature maps\n",
    "    # (c,d)=dimensions of a f. map (N=c*d)\n",
    "\n",
    "    grams = []\n",
    "\n",
    "    for i in range(a):\n",
    "        features = input[i].view(b, c * d)  # resise F_XL into \\hat F_XL\n",
    "        G = torch.mm(features, features.t())  # compute the gram product\n",
    "        grams.append(G.div(b * c * d))\n",
    "\n",
    "    return grams\n",
    "\n",
    "\n",
    "def gram_matrix_3d(input, pool_factor=1):\n",
    "    # taken from: https://pytorch.org/tutorials/advanced/neural_style_tutorial.html\n",
    "    a, b, c, d, e = input.size()  # a=batch size(=1)\n",
    "    # b=number of feature maps\n",
    "    # (c,d)=dimensions of a f. map (N=c*d)\n",
    "\n",
    "    grams = []\n",
    "\n",
    "    for i in range(a):\n",
    "        features = input[i].view(b, c * d * e)  # resise F_XL into \\hat F_XL\n",
    "        G = torch.mm(features, features.t())  # compute the gram product\n",
    "        if pool_factor==1:\n",
    "            grams.append(G.div(b * c * d * e))\n",
    "        else:\n",
    "            pool = nn.MaxPool2d(pool_factor)\n",
    "            gram = G.div(b * c * d * e)\n",
    "            gram_pooled = pool(gram[None, :])\n",
    "            grams.append(gram_pooled[0])\n",
    "\n",
    "    return grams\n",
    "\n",
    "def gram_hook(m, input, output):\n",
    "    grammatrices.append(gram_matrix_3d(input[0]))\n",
    "\n",
    "def register_hooks():\n",
    "    for layer in gramlayers:\n",
    "        layer.register_forward_hook(gram_hook)\n",
    "        \n",
    "def gram_hook_2d(m, input, output):\n",
    "    grammatrices.append(gram_matrix(input[0]))\n",
    "\n",
    "def register_hooks_2d(layers):\n",
    "    for layer in layers:\n",
    "        layer.register_forward_hook(gram_hook_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stylemodel = tvmodels.resnet50(pretrained=True)\n",
    "gramlayers = [stylemodel.layer2[-1].conv1]\n",
    "register_hooks_2d(gramlayers)\n",
    "stylemodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import active_dynamicmemory.LIDCutils as lutils\n",
    "dl_base = DataLoader(LIDCBatch('/project/catinous/lungnodulesfinallndbBig.csv',\n",
    "                                            iterations=None,\n",
    "                                            batch_size=4,\n",
    "                                            split=['base']),\n",
    "                              batch_size=4, num_workers=8, drop_last=True,\n",
    "                              collate_fn=lutils.collate_fn)\n",
    "\n",
    "dl_train = DataLoader(LIDCBatch('/project/catinous/lungnodulesfinallndbBig.csv',\n",
    "                                            iterations=None,\n",
    "                                            batch_size=4,\n",
    "                                            split=['train']),\n",
    "                              batch_size=4, num_workers=8, drop_last=True,\n",
    "                              collate_fn=lutils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_grams = []\n",
    "for batch in dl_base:\n",
    "    grammatrices=[]\n",
    "    _ = stylemodel(torch.stack(batch[0]))\n",
    "    \n",
    "    for i in range(len(batch)):\n",
    "        base_grams.append(grammatrices[0][i].detach().cpu().numpy().flatten())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grammatrices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = []\n",
    "emb_grams = []\n",
    "for batch in dl_train:\n",
    "    grammatrices=[]\n",
    "    _ = stylemodel(torch.stack(batch[0]))\n",
    "    \n",
    "    for i in range(len(batch)):\n",
    "        emb_grams.append(grammatrices[0][i].detach().cpu().numpy().flatten())    \n",
    "    for scanner in batch[2]:\n",
    "        if scanner == 'ges':\n",
    "            colors.append(0)\n",
    "        elif scanner == 'geb':\n",
    "            colors.append(1)\n",
    "        elif scanner=='sie':\n",
    "            colors.append(2)\n",
    "        else:\n",
    "            colors.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30, random_state=1).fit(base_grams)\n",
    "#trans_grams = pca.transform(emb_grams)\n",
    "trans_base = pca.transform(base_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.16928231e-04  1.63341911e-04  1.30171633e-04 -1.15853319e-04\n",
      "  3.86028857e-05  1.96249395e-05 -8.13421445e-06 -8.88437801e-06\n",
      "  1.49158795e-05  9.12531830e-06  3.86888766e-05 -1.60823763e-05\n",
      " -4.94444787e-05  1.32860261e-06  6.52455567e-06 -9.15483000e-06\n",
      " -1.21693476e-06 -5.23677750e-06 -6.79999902e-06 -3.71567634e-06\n",
      "  5.67962578e-06  7.16657842e-07 -9.06617616e-06  3.48899602e-06\n",
      " -1.11281512e-05  4.90573492e-06 -3.63730138e-06 -3.78311466e-06\n",
      "  4.20668795e-06  5.35542320e-06]\n"
     ]
    }
   ],
   "source": [
    "init_center = trans_base[:128].mean(axis=0)\n",
    "print(init_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=30)\n",
    "elements_tsne = tsne.fit_transform(emb_grams)\n",
    "plt.scatter(elements_tsne[:, 0], elements_tsne[:, 1], c=colors, cmap='Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams = []\n",
    "grams.extend(trans_base)\n",
    "grams.extend(trans_grams)\n",
    "\n",
    "\n",
    "grams.append(trans_grams[:135].mean(axis=0)) #center ges\n",
    "grams.append(trans_grams[136:301].mean(axis=0)) #center geb\n",
    "grams.append(trans_grams[302:403].mean(axis=0)) #center sie\n",
    "grams.append(trans_grams[403:].mean(axis=0)) #center lndb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f20cbd3cc50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=30)\n",
    "elements_tsne = tsne.fit_transform(grams)\n",
    "plt.scatter(elements_tsne[:, 0][len(base_grams):-4], elements_tsne[:, 1][len(base_grams):-4], c=colors, cmap='Set1')\n",
    "plt.scatter(elements_tsne[:, 0][:len(base_grams)], elements_tsne[:, 1][:len(base_grams)], cmap='Set1', marker='x')\n",
    "\n",
    "plt.scatter(elements_tsne[:, 0][-4:], elements_tsne[:, 1][-4:], marker='+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_ges = trans_grams[:135].mean(axis=0)\n",
    "center_geb = trans_grams[136:301].mean(axis=0)\n",
    "center_sie = trans_grams[302:403].mean(axis=0)\n",
    "center_lndb = trans_grams[403:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryItem():\n",
    "\n",
    "    def __init__(self, img, target, filepath, scanner, current_grammatrix=None, pseudo_domain=None):\n",
    "        self.img = img\n",
    "        self.target = target\n",
    "        self.filepath = filepath\n",
    "        self.scanner = scanner\n",
    "        self.counter = 0\n",
    "        self.traincounter = 0\n",
    "        self.deleteflag = False\n",
    "        self.pseudo_domain = pseudo_domain\n",
    "        self.current_grammatrix = current_grammatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_count(memory, pd):\n",
    "    c = 0\n",
    "    for mi in memory:\n",
    "        if mi.pseudo_domain==pd:\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def find_insert_position(memorylist):\n",
    "    for idx, item in enumerate(memorylist):\n",
    "        if item.deleteflag:\n",
    "            return idx\n",
    "    return -1\n",
    "\n",
    "def find_random_insert(memorylist, pd):\n",
    "    positions = []\n",
    "    for idx, item in enumerate(memorylist):\n",
    "        if item.pseudo_domain==pd:\n",
    "            positions.append(idx)\n",
    "    random.shuffle(positions)\n",
    "    return positions[0]\n",
    "\n",
    "def get_gm_list(memory):\n",
    "    grams = []\n",
    "    for mi in memory:\n",
    "        grams.append(mi.current_grammatrix)\n",
    "    return grams\n",
    "\n",
    "def flag_for_deletion(memory, domain_count, max_per_domain):\n",
    "    for k in range(domain_count):\n",
    "        domain_count = get_domain_count(memory, k)\n",
    "        if domain_count>max_per_domain:\n",
    "            todelete = domain_count-max_per_domain\n",
    "            for item in memory:\n",
    "                if todelete>0:\n",
    "                    if item.pseudo_domain==k:\n",
    "                        if not item.deleteflag:\n",
    "                            item.deleteflag = True\n",
    "\n",
    "                        todelete -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_list = []\n",
    "\n",
    "for tb in trans_base[:memory_maximum]:\n",
    "    mi = MemoryItem(None, None, None, 0, current_grammatrix=tb, pseudo_domain=0)\n",
    "    init_distances.append(mean_squared_error(tb, init_center))\n",
    "    memory_list.append(mi)\n",
    "\n",
    "gm_list = get_gm_list(memory_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "[ 1  2  3  4  6  7 11 14 15 16 17 18 19 20 21 22] remove\n",
      "new maximum 64\n",
      "outliers after removing 7\n",
      "inlier 0 1\n",
      "inlier 0 1\n",
      "inlier 0 1\n",
      "inlier 0 0\n",
      "inlier 0 1\n",
      "inlier 0 1\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 1\n",
      "inlier 0 0\n",
      "inlier 0 1\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 1\n",
      "inlier 0 0\n",
      "inlier 0 1\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "inlier 0 0\n",
      "[ 8  9 10 11 12 13 14 15 16 17 18 19 20 23 24 26 27 28 29] remove\n",
      "new maximum 42\n",
      "outliers after removing 11\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "[10 11 12 13 14 15 16 17 18 19] remove\n",
      "new maximum 32\n",
      "outliers after removing 10\n",
      "inlier 1 3\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 3\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 3\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 3\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 3\n",
      "inlier 1 3\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 3\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 3\n",
      "inlier 1 3\n",
      "inlier 1 3\n",
      "inlier 1 2\n",
      "inlier 1 3\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 3\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 3\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 3\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 3\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 1 2\n",
      "inlier 2 0\n",
      "inlier 2 1\n",
      "inlier 2 0\n",
      "inlier 2 0\n",
      "inlier 2 0\n",
      "inlier 2 0\n",
      "inlier 2 0\n",
      "inlier 2 1\n",
      "inlier 2 0\n",
      "inlier 2 0\n",
      "inlier 2 0\n",
      "inlier 2 1\n",
      "inlier 2 1\n",
      "inlier 2 0\n",
      "inlier 2 0\n",
      "inlier 2 1\n",
      "inlier 2 0\n",
      "inlier 2 1\n",
      "inlier 2 1\n",
      "inlier 2 0\n",
      "inlier 2 1\n",
      "inlier 2 0\n",
      "inlier 2 0\n",
      "inlier 2 0\n",
      "inlier 2 0\n",
      "inlier 2 0\n",
      "[ 3 20 27 28 31 32 34 35 36] remove\n",
      "new maximum 25\n",
      "outliers after removing 28\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 2 1\n",
      "inlier 2 4\n",
      "inlier 2 0\n",
      "inlier 2 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "[18 28 29 30 31 33 34 35 36 37 38 39 43 44 45 47 48 49 50] remove\n",
      "new maximum 21\n",
      "outliers after removing 32\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 2\n",
      "inlier 3 0\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 0\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "[ 6 10 28 29 30 31 32 33 34 35 37 38 39 41 42 45 46 47 48 49 50 51 52 53\n",
      " 54] remove\n",
      "new maximum 18\n",
      "outliers after removing 30\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 6\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 6\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 6\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 6\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 6\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 6\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 6\n",
      "inlier 3 1\n",
      "inlier 3 2\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 0\n",
      "inlier 3 4\n",
      "inlier 3 0\n",
      "inlier 3 4\n",
      "inlier 3 0\n",
      "inlier 3 4\n",
      "inlier 3 0\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 0\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 6\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 1\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n",
      "inlier 3 2\n",
      "inlier 3 5\n",
      "inlier 3 4\n",
      "inlier 3 5\n"
     ]
    }
   ],
   "source": [
    "memory_maximum = 128\n",
    "maximum_per_domain = 128\n",
    "memory_list = []\n",
    "\n",
    "init_center = trans_base[:memory_maximum].mean(axis=0)\n",
    "init_distances = []\n",
    "for tb in trans_base[:memory_maximum]:\n",
    "    mi = MemoryItem(None, None, None, 0, current_grammatrix=tb, pseudo_domain=0)\n",
    "    init_distances.append(mean_squared_error(tb, init_center))\n",
    "    memory_list.append(mi)\n",
    "    \n",
    "max_distances = [np.array(init_distances).mean() * 2]\n",
    "centers = [init_center]\n",
    "\n",
    "outliers = []\n",
    "outliers_label = []\n",
    "inliers = {0:[]}\n",
    "\n",
    "for i, tr in enumerate(trans_grams):\n",
    "    \n",
    "    out = True\n",
    "    for j, (center, md) in enumerate(zip(centers, max_distances)):\n",
    "        if mean_squared_error(tr, center)<md:\n",
    "            out=False\n",
    "            print('inlier', colors[i], j)\n",
    "            mi = MemoryItem(None, None, None, colors[i], current_grammatrix=tr, pseudo_domain=j)\n",
    "            if get_domain_count(memory_list, j)<maximum_per_domain:\n",
    "                idx = find_insert_position(memory_list)\n",
    "                if idx!=-1:\n",
    "                    memory_list[idx] = mi\n",
    "                else:\n",
    "                    print('that shouldnt happen')\n",
    "            else:\n",
    "                #replace a random element\n",
    "                idx = find_random_insert(memory_list, j)\n",
    "                memory_list[idx] = mi\n",
    "    if out:\n",
    "        mi = MemoryItem(None, None, None, colors[i], current_grammatrix=tr, pseudo_domain=None)\n",
    "        outliers.append(mi)        \n",
    "        \n",
    "    if len(outliers)>10:\n",
    "        distances = squareform(pdist(get_gm_list(outliers)))\n",
    "        \n",
    "        distance_list = [np.array(sorted(d)[:10]).sum() for d in distances]\n",
    "        #print(sorted(distance_list)[5], len(outliers))\n",
    "        if sorted(distance_list)[5]<0.02:\n",
    "            to_remove = np.where(np.array(distance_list)<0.025)[0]\n",
    "            print(to_remove, 'remove')\n",
    "            new_cluster = []\n",
    "            new_domain = len(centers)\n",
    "            \n",
    "            maximum_per_domain = int(memory_maximum / (len(centers)+1))\n",
    "            flag_for_deletion(memory_list, len(centers), maximum_per_domain)\n",
    "            print('new maximum', maximum_per_domain)\n",
    "            \n",
    "            for k, r in enumerate(to_remove):\n",
    "                elem = outliers.pop(r-k)\n",
    "                elem.pseudo_domain = new_domain\n",
    "                new_cluster.append(elem)\n",
    "                \n",
    "            #insert cluster to memory list\n",
    "            idx = find_insert_position(memory_list)\n",
    "            for mi in new_cluster:\n",
    "                if idx!=-1:\n",
    "                    memory_list[idx] = mi\n",
    "                else:\n",
    "                    print('no insert position')\n",
    "                        \n",
    "            print('outliers after removing', len(outliers))\n",
    "            \n",
    "            init_distances = []\n",
    "            new_center = np.array(get_gm_list(new_cluster)).mean(axis=0)\n",
    "            centers.append(new_center)\n",
    "            for cm in get_gm_list(new_cluster):\n",
    "                init_distances.append(mean_squared_error(cm, new_center))\n",
    "            \n",
    "            max_distances.append(np.array(init_distances).mean() * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dict()\n",
    "for k in range(len(max_distances)):\n",
    "    counts[k] = []\n",
    "    \n",
    "for mi in memory_list:\n",
    "    counts[mi.pseudo_domain].append(mi.scanner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 2, 3]), array([ 5, 14,  6]))\n",
      "(array([3]), array([20]))\n",
      "(array([3]), array([18]))\n",
      "(array([1]), array([16]))\n",
      "(array([3]), array([20]))\n",
      "(array([3]), array([20]))\n",
      "(array([3]), array([9]))\n"
     ]
    }
   ],
   "source": [
    "for k in counts:\n",
    "    print(np.unique(counts[k], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0350004913369104"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = [np.array(d).sum() for d in distances]\n",
    "sorted(sd)[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "coutlier = np.array(outliers).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5791244596547916e-07"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(coutlier, init_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2803121860030403e-07"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for tr in trans_grams:\n",
    "    errors.append([mean_squared_error(center_ges, tr), mean_squared_error(center_geb, tr), mean_squared_error(center_sie, tr), mean_squared_error(center_lndb, tr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.336941308839582e-07"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest = np.argmin(errors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ges_grams = trans_grams[:127]\n",
    "random.shuffle(ges_grams)\n",
    "\n",
    "geb_grams = trans_grams[148:290]\n",
    "random.shuffle(geb_grams)\n",
    "\n",
    "sie_grams = trans_grams[296:393]\n",
    "random.shuffle(sie_grams)\n",
    "\n",
    "lndb_grams = trans_grams[407:]\n",
    "random.shuffle(lndb_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(contamination=0.1, random_state=1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ges_clf = IsolationForest(n_estimators=100, contamination=0.10, random_state=1)\n",
    "ges_clf.fit(ges_grams[:10])\n",
    "\n",
    "geb_clf = IsolationForest(n_estimators=100, contamination=0.10, random_state=1)\n",
    "geb_clf.fit(geb_grams[:10])\n",
    "\n",
    "sie_clf = IsolationForest(n_estimators=100, contamination=0.10, random_state=1)\n",
    "sie_clf.fit(sie_grams[:10])\n",
    "\n",
    "lndb_clf = IsolationForest(n_estimators=100, contamination=0.10, random_state=1)\n",
    "lndb_clf.fit(lndb_grams[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(bootstrap=True, contamination=0.1, n_estimators=10,\n",
       "                random_state=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ges_clf = IsolationForest(n_estimators=10, contamination=0.10, bootstrap=True, random_state=1)\n",
    "ges_clf.fit(ges_grams[:10])\n",
    "\n",
    "geb_clf = IsolationForest(n_estimators=10, contamination=0.10,bootstrap=True, random_state=1)\n",
    "geb_clf.fit(geb_grams[:10])\n",
    "\n",
    "sie_clf = IsolationForest(n_estimators=10, contamination=0.10, bootstrap=True, random_state=1)\n",
    "sie_clf.fit(sie_grams[:10])\n",
    "\n",
    "lndb_clf = IsolationForest(n_estimators=10, contamination=0.10, bootstrap=True, random_state=1)\n",
    "lndb_clf.fit(lndb_grams[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i, g in enumerate(emb_grams):\n",
    "    preds = [ges_clf.decision_function(g.reshape(1, -1)),\n",
    "            geb_clf.decision_function(g.reshape(1, -1)),\n",
    "            sie_clf.decision_function(g.reshape(1, -1)),\n",
    "            lndb_clf.decision_function(g.reshape(1, -1))]\n",
    "    \n",
    "    idx = np.argmax(preds)\n",
    "    if preds[idx]>0:\n",
    "        pred.append(idx)\n",
    "    else:\n",
    "        pred.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ges_grams = elements_tsne[:127]\n",
    "random.shuffle(ges_grams)\n",
    "\n",
    "\n",
    "ges_clf = IsolationForest(n_estimators=50, contamination='auto', random_state=1)\n",
    "ges_clf.fit(ges_grams[:10])\n",
    "\n",
    "pred = ges_clf.predict(ges_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(trans_grams[0], trans_grams[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.60449902e-04, -1.13770359e-03, -1.13779250e-03, -1.89725398e-04,\n",
       "        4.17953086e-04,  2.37943290e-04,  6.20267548e-04, -1.33412024e-04,\n",
       "       -2.32306083e-04,  7.43584444e-06,  5.21449773e-04, -1.64495309e-04,\n",
       "       -9.02244298e-05, -2.27923119e-04,  3.98912319e-04, -1.03680396e-04,\n",
       "        2.45595149e-04, -1.38922704e-04,  1.34853508e-05,  5.82022303e-05,\n",
       "        5.51452795e-05,  5.54328128e-05,  1.59445060e-04, -1.38521077e-04,\n",
       "       -6.97105485e-05, -8.22408493e-05, -7.84007895e-05,  5.24961286e-05,\n",
       "       -6.00560773e-05, -5.32778593e-05])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_grams[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0],\n",
       "       [112,  15]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(len(pred)*[1], np.array(pred)==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0],\n",
       "       [74, 53]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(len(pred)*[1], np.array(pred)==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[707,   7],\n",
       "       [149,  17]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.array(colors)==1, np.array(pred)==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0],\n",
       "       [  4,  54,   2,  76,   0],\n",
       "       [ 20,  25,  66,  19,  35],\n",
       "       [  1,  46,   3,  49,   2],\n",
       "       [ 12,  15, 114, 160, 177]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.10\n",
    "confusion_matrix(colors, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0],\n",
       "       [ 14,  38,   1,  83,   0],\n",
       "       [105,   3,  22,  15,  20],\n",
       "       [ 22,  20,   0,  58,   1],\n",
       "       [ 82,   4,  59, 172, 161]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#auto\n",
    "confusion_matrix(colors, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0],\n",
       "       [ 11,  52,   2,  70,   1],\n",
       "       [112,   0,  53,   0,   0],\n",
       "       [  5,   6,   0,  90,   0],\n",
       "       [119,   1,  15,  68, 275]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#est 100 auto\n",
    "confusion_matrix(colors, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0],\n",
       "       [  1,  21,   1, 112,   1],\n",
       "       [ 46,   0,  96,  16,   7],\n",
       "       [  1,   0,   0, 100,   0],\n",
       "       [ 25,   0,  24,  91, 338]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#est 100 0.10\n",
    "confusion_matrix(colors, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0],\n",
       "       [  2,  81,  10,  39,   4],\n",
       "       [  2,  19, 107,  14,  23],\n",
       "       [  0,  58,   1,  41,   1],\n",
       "       [  2,  73, 150,  51, 202]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.10 bootstrap\n",
    "confusion_matrix(colors, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/project/catinous/lungnodulesfinallndbBig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>scanner</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>bin_malignancy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>883</td>\n",
       "      <td>883</td>\n",
       "      <td>883</td>\n",
       "      <td>883</td>\n",
       "      <td>883</td>\n",
       "      <td>883</td>\n",
       "      <td>883</td>\n",
       "      <td>883</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset  scanner  patient_id  image   x1   x2   y1   y2  bin_malignancy\n",
       "split                                                                         \n",
       "base       253      253         253    253  253  253  253  253             253\n",
       "test       220      220         220    220  220  220  220  220             220\n",
       "train      883      883         883    883  883  883  883  883             883\n",
       "val        141      141         141    141  141  141  141  141             141"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('split').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 110, 88, 44)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(883/5), round(883/8), round(883/10), round(883/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test",
   "language": "python",
   "name": "venv_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
