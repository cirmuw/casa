settings:
    LOGGING_DIR: '/project/catinous/active_catinous/MELBA/log/tensorboard_logs/'
    TRAINED_MODELS_DIR: '/project/catinous/active_catinous/MELBA/output/trained_models/'
    TRAINED_MEMORY_DIR: '/project/catinous/active_catinous/MELBA/output/trained_memory/'
    RESULT_DIR: '/project/catinous/active_catinous/MELBA/output/results/'

trainparams:
    continuous: False
    use_memory: False
    datasetfile: '/project/catinous/lungnodulesfinallndbBig.csv'
    batch_size: 8
    task: 'lidc'
    noncontinuous_steps: 5000 #1000, 1000, 1000
    noncontinuous_train_splits: ['base', 'train']
    order: ['ges', 'geb', 'sie', 'lndb']
    scanner: 'geb'
    base_model: null
    run_postfix: 1
    seed: 1 # 6511620
    val_check_interval: 50
    droprate: 0.0 #0.0, 0.0, 0.0
    learning_rate: 0.0001 #0.0001
    gradient_clip_val: 0.5 #0.5, 0.5, 0.5